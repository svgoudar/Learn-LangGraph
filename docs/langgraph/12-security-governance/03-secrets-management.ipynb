{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65b637e-1d37-4e87-a2e1-2097a248af3f",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Secret Management\n",
    "\n",
    "Secret management in LangGraph refers to the **secure storage, access, rotation, and usage of sensitive credentials** (API keys, tokens, passwords, certificates) across graph execution, agents, tools, and environments—**without exposing them in code, logs, state, or memory**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Why Secret Management Matters in LangGraph**\n",
    "\n",
    "LangGraph workflows interact with:\n",
    "\n",
    "* LLM APIs (OpenAI, Anthropic, etc.)\n",
    "* Databases\n",
    "* Vector stores\n",
    "* Internal services\n",
    "* Cloud resources\n",
    "\n",
    "Without proper secret management, systems risk:\n",
    "\n",
    "| Risk                  | Impact             |\n",
    "| --------------------- | ------------------ |\n",
    "| Credential leakage    | Security breach    |\n",
    "| Model abuse           | Cost explosion     |\n",
    "| Compliance violations | Legal risk         |\n",
    "| System compromise     | Production failure |\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Design Principles**\n",
    "\n",
    "| Principle             | Description                       |\n",
    "| --------------------- | --------------------------------- |\n",
    "| No secrets in code    | Never hardcode keys               |\n",
    "| No secrets in state   | State must be serializable & safe |\n",
    "| Environment isolation | Dev / Staging / Prod separation   |\n",
    "| Least privilege       | Limit access scope                |\n",
    "| Rotation              | Regular secret updates            |\n",
    "| Auditability          | Track access & usage              |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Where Secrets Live in LangGraph Systems**\n",
    "\n",
    "LangGraph itself does **not store secrets**.\n",
    "It consumes secrets from **secure external sources**.\n",
    "\n",
    "| Layer      | Storage                   |\n",
    "| ---------- | ------------------------- |\n",
    "| Local dev  | `.env` files              |\n",
    "| Server     | OS environment variables  |\n",
    "| Cloud      | Secret Manager / Vault    |\n",
    "| Containers | Kubernetes Secrets        |\n",
    "| CI/CD      | Secure pipeline variables |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Standard Secret Flow in LangGraph**\n",
    "\n",
    "```\n",
    "Secret Store → Environment → Tool/LLM Client → LangGraph Node\n",
    "```\n",
    "\n",
    "**Secrets are injected only at runtime.**\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Accessing Secrets in LangGraph Nodes**\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "def llm_node(state):\n",
    "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    ...\n",
    "```\n",
    "\n",
    "**Never** put secrets in:\n",
    "\n",
    "* Graph state\n",
    "* Node return values\n",
    "* Logs\n",
    "* Checkpoints\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Using Secrets with Tools**\n",
    "\n",
    "```python\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Production-Grade Secret Backends**\n",
    "\n",
    "| Platform   | Solution        |\n",
    "| ---------- | --------------- |\n",
    "| AWS        | Secrets Manager |\n",
    "| Azure      | Key Vault       |\n",
    "| GCP        | Secret Manager  |\n",
    "| Kubernetes | K8s Secrets     |\n",
    "| Enterprise | HashiCorp Vault |\n",
    "\n",
    "Example (AWS):\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "client = boto3.client(\"secretsmanager\")\n",
    "secret = client.get_secret_value(SecretId=\"openai_key\")[\"SecretString\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Preventing Secret Leakage**\n",
    "\n",
    "| Control            | How                       |\n",
    "| ------------------ | ------------------------- |\n",
    "| Log filtering      | Never log env             |\n",
    "| State sanitization | Validate outputs          |\n",
    "| Access control     | Node-level permissions    |\n",
    "| Redaction          | Mask tokens               |\n",
    "| Memory exclusion   | Do not store in vector DB |\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Secret Rotation Strategy**\n",
    "\n",
    "1. Store versioned secrets\n",
    "2. Rotate on schedule\n",
    "3. Update environment\n",
    "4. Restart LangGraph workers\n",
    "5. Verify health\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Secure Deployment Pattern**\n",
    "\n",
    "```\n",
    "Kubernetes Pod\n",
    "   |\n",
    "Env Injection from K8s Secrets\n",
    "   |\n",
    "LangGraph Runtime\n",
    "   |\n",
    "LLM & Tools\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Compliance & Governance**\n",
    "\n",
    "| Requirement       | Implementation            |\n",
    "| ----------------- | ------------------------- |\n",
    "| Access audit      | Central secret manager    |\n",
    "| Encryption        | At rest + in transit      |\n",
    "| RBAC              | Who can read which secret |\n",
    "| Key expiration    | Mandatory rotation        |\n",
    "| Incident response | Immediate revoke          |\n",
    "\n",
    "---\n",
    "\n",
    "### **12. Anti-Patterns (Never Do This)**\n",
    "\n",
    "```python\n",
    "api_key = \"sk-123...\"   # ❌\n",
    "state[\"api_key\"] = os.environ[\"OPENAI_API_KEY\"]  # ❌\n",
    "print(os.environ)  # ❌\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **13. Minimal Secure Example**\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph\n",
    "import os\n",
    "\n",
    "def agent_node(state):\n",
    "    llm = ChatOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    ...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **14. Mental Model**\n",
    "\n",
    "> **LangGraph orchestrates behavior.\n",
    "> Your platform governs secrets.**\n",
    "\n",
    "LangGraph remains **stateless and secret-agnostic**, while your infrastructure ensures **secure execution**.\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34284650-0028-4bcc-ba03-7ab41f0590c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent is an iterative optimization algorithm used to minimize the error or loss function of a machine learning model by adjusting the model's parameters in the direction of steepest descent of the gradient.\n"
     ]
    }
   ],
   "source": [
    "# Secure, production-style LangGraph setup with secret management (single cell demo)\n",
    "\n",
    "import os\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ---- 1. Assume secret is injected by environment (not in code!) ----\n",
    "# Example: export OPENAI_API_KEY=sk-...\n",
    "\n",
    "assert \"OPENAI_API_KEY\" in os.environ, \"Missing secret in environment\"\n",
    "\n",
    "# ---- 2. Define State ----\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "# ---- 3. Define Node that consumes secret safely ----\n",
    "def llm_node(state: State):\n",
    "    llm = ChatOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    response = llm.invoke(state[\"question\"])\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# ---- 4. Build Graph ----\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"llm\", llm_node)\n",
    "builder.set_entry_point(\"llm\")\n",
    "builder.add_edge(\"llm\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# ---- 5. Execute (no secret ever enters state or logs) ----\n",
    "result = graph.invoke({\"question\": \"Explain gradient descent in one sentence.\"})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12077325-88c8-4fa1-8319-68a08f369c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "py312env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
