{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32aec06c",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Worker Pool\n",
    "\n",
    "A **Worker Pool** in LangGraph is a **concurrency and scalability mechanism** that allows multiple independent execution units (workers) to process graph tasks in parallel.\n",
    "It transforms a single-threaded agent system into a **high-throughput, production-grade distributed execution engine**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Motivation**\n",
    "\n",
    "Large LLM workflows require:\n",
    "\n",
    "* Parallel tool execution\n",
    "* Concurrent agent reasoning\n",
    "* High throughput for multiple users\n",
    "* Fault isolation between tasks\n",
    "\n",
    "A Worker Pool enables:\n",
    "\n",
    "> **Scalable, parallel, resilient execution of LangGraph nodes.**\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Conceptual Model**\n",
    "\n",
    "```\n",
    "Incoming Requests\n",
    "        |\n",
    "   Graph Scheduler\n",
    "        |\n",
    "  ┌───────────────┐\n",
    "  │  Worker Pool  │\n",
    "  └───────────────┘\n",
    "   |     |     |\n",
    "Worker1 Worker2 Worker3 ...\n",
    "   |     |     |\n",
    " Execute Nodes in Parallel\n",
    "```\n",
    "\n",
    "Each worker is an **independent execution context** capable of running one or more graph steps.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Architecture Components**\n",
    "\n",
    "| Component        | Responsibility                |\n",
    "| ---------------- | ----------------------------- |\n",
    "| Graph Scheduler  | Decides which node runs next  |\n",
    "| Task Queue       | Holds pending node executions |\n",
    "| Worker           | Executes node logic           |\n",
    "| State Store      | Shared state persistence      |\n",
    "| Result Collector | Merges node outputs           |\n",
    "| Failure Manager  | Retries and recovery          |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. How LangGraph Uses Worker Pools**\n",
    "\n",
    "LangGraph’s runtime schedules node execution based on:\n",
    "\n",
    "* Graph topology\n",
    "* State readiness\n",
    "* Conditional routing\n",
    "* Parallel branches\n",
    "\n",
    "Parallel branches are **dispatched to different workers** automatically.\n",
    "\n",
    "```\n",
    "Fan-out → Worker Pool → Fan-in\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Example: Parallel Execution with Worker Pool**\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class State(TypedDict):\n",
    "    a: int\n",
    "    b: int\n",
    "    c: int\n",
    "\n",
    "def task1(state): return {\"a\": 1}\n",
    "def task2(state): return {\"b\": 2}\n",
    "def task3(state): return {\"c\": 3}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"t1\", task1)\n",
    "builder.add_node(\"t2\", task2)\n",
    "builder.add_node(\"t3\", task3)\n",
    "\n",
    "builder.set_entry_point(\"t1\")\n",
    "builder.add_edge(\"t1\", \"t2\")\n",
    "builder.add_edge(\"t1\", \"t3\")\n",
    "builder.add_edge(\"t2\", END)\n",
    "builder.add_edge(\"t3\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "result = graph.invoke({}, config={\"max_workers\": 3})\n",
    "print(result)\n",
    "```\n",
    "\n",
    "`t2` and `t3` are executed **concurrently** by different workers.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Worker Pool Variants**\n",
    "\n",
    "| Variant             | Use Case              |\n",
    "| ------------------- | --------------------- |\n",
    "| Thread Pool         | I/O-bound tasks       |\n",
    "| Process Pool        | CPU-heavy computation |\n",
    "| Async Workers       | High-concurrency I/O  |\n",
    "| Distributed Workers | Multi-machine scaling |\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Production-Grade Features**\n",
    "\n",
    "| Feature         | Description                  |\n",
    "| --------------- | ---------------------------- |\n",
    "| Dynamic Scaling | Adjust workers based on load |\n",
    "| Backpressure    | Prevent overload             |\n",
    "| Work Stealing   | Idle workers take tasks      |\n",
    "| Retry Policies  | Fault recovery               |\n",
    "| Timeout Control | Prevent hung workers         |\n",
    "| Isolation       | Crash containment            |\n",
    "\n",
    "---\n",
    "\n",
    "### **8. When to Use Worker Pools**\n",
    "\n",
    "Use worker pools when your graph:\n",
    "\n",
    "* Has parallel branches\n",
    "* Executes expensive tools\n",
    "* Runs multi-agent workflows\n",
    "* Serves many concurrent users\n",
    "* Requires high availability\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Performance Impact**\n",
    "\n",
    "| Without Worker Pool   | With Worker Pool  |\n",
    "| --------------------- | ----------------- |\n",
    "| Sequential            | Parallel          |\n",
    "| Low throughput        | High throughput   |\n",
    "| High latency          | Low latency       |\n",
    "| Single failure domain | Isolated failures |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Mental Model**\n",
    "\n",
    "Think of LangGraph as a **distributed operating system for LLM workflows**:\n",
    "\n",
    "* Graph = Program\n",
    "* State = Memory\n",
    "* Nodes = Instructions\n",
    "* Worker Pool = CPU cores\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152acfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final State: {'results': ['A', 'B', 'C', 'Collected: A, B, C']}\n",
      "Execution Time: 1.39 seconds\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import time\n",
    "import random\n",
    "import operator\n",
    "\n",
    "# ---------- 1. Define Shared State with Reducer ----------\n",
    "class State(TypedDict):\n",
    "    results: Annotated[list, operator.add]\n",
    "\n",
    "# ---------- 2. Define Start and Parallel Tasks ----------\n",
    "def start(state: State):\n",
    "    return state\n",
    "\n",
    "def worker_a(state: State):\n",
    "    time.sleep(random.uniform(0.5, 1.5))\n",
    "    return {\"results\": [\"A\"]}\n",
    "\n",
    "def worker_b(state: State):\n",
    "    time.sleep(random.uniform(0.5, 1.5))\n",
    "    return {\"results\": [\"B\"]}\n",
    "\n",
    "def worker_c(state: State):\n",
    "    time.sleep(random.uniform(0.5, 1.5))\n",
    "    return {\"results\": [\"C\"]}\n",
    "\n",
    "def collect(state: State):\n",
    "    return {\"results\": [f\"Collected: {', '.join(sorted(state['results']))}\"]}\n",
    "\n",
    "# ---------- 3. Build Graph ----------\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"start\", start)\n",
    "builder.add_node(\"A\", worker_a)\n",
    "builder.add_node(\"B\", worker_b)\n",
    "builder.add_node(\"C\", worker_c)\n",
    "builder.add_node(\"collect\", collect)\n",
    "\n",
    "builder.set_entry_point(\"start\")\n",
    "\n",
    "# Fan-out: start branches to all workers\n",
    "builder.add_edge(\"start\", \"A\")\n",
    "builder.add_edge(\"start\", \"B\")\n",
    "builder.add_edge(\"start\", \"C\")\n",
    "\n",
    "# Fan-in: all workers converge to collect\n",
    "builder.add_edge(\"A\", \"collect\")\n",
    "builder.add_edge(\"B\", \"collect\")\n",
    "builder.add_edge(\"C\", \"collect\")\n",
    "\n",
    "builder.add_edge(\"collect\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# ---------- 4. Execute with Worker Pool ----------\n",
    "start = time.time()\n",
    "\n",
    "result = graph.invoke({\"results\": []}, config={\"max_workers\": 3})\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Final State:\", result)\n",
    "print(\"Execution Time:\", round(end - start, 2), \"seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
