{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Execution Engine\n",
    "\n",
    "The **Execution Engine** in LangGraph is the **runtime system** responsible for transforming a compiled graph definition into a live, fault-tolerant, stateful computation.\n",
    "It coordinates **node execution, state transitions, control flow, persistence, concurrency, and recovery**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Conceptual Role**\n",
    "\n",
    "LangGraph programs are **not scripts**; they are **state machines**.\n",
    "The execution engine acts as the **state machine interpreter**.\n",
    "\n",
    "$$\n",
    "\\text{Graph Definition} \\xrightarrow{\\text{compile}} \\text{Executable Plan} \\xrightarrow{\\text{execute}} \\text{Running System}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Responsibilities of the Execution Engine**\n",
    "\n",
    "| Responsibility    | Description                           |\n",
    "| ----------------- | ------------------------------------- |\n",
    "| Node Scheduling   | Determines which node runs next       |\n",
    "| State Management  | Reads, merges, and writes state       |\n",
    "| Control Flow      | Evaluates edges and conditions        |\n",
    "| Concurrency       | Runs independent nodes in parallel    |\n",
    "| Persistence       | Saves checkpoints & resumes execution |\n",
    "| Fault Tolerance   | Retries, recovery, timeouts           |\n",
    "| Observability     | Emits traces, logs, metrics           |\n",
    "| Human Interaction | Supports interrupts & approvals       |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Execution Lifecycle**\n",
    "\n",
    "### **(a) Graph Compilation**\n",
    "\n",
    "```python\n",
    "graph = builder.compile()\n",
    "```\n",
    "\n",
    "Compilation produces an **optimized execution plan**:\n",
    "\n",
    "* Node dependency graph\n",
    "* Transition table\n",
    "* State reducers\n",
    "* Validation hooks\n",
    "\n",
    "---\n",
    "\n",
    "### **(b) Invocation**\n",
    "\n",
    "```python\n",
    "result = graph.invoke(initial_state)\n",
    "```\n",
    "\n",
    "The engine creates a **new execution thread**:\n",
    "\n",
    "| Runtime Object    | Purpose                   |\n",
    "| ----------------- | ------------------------- |\n",
    "| Thread ID         | Unique execution instance |\n",
    "| Session           | Logical grouping          |\n",
    "| State Store       | Persistent working memory |\n",
    "| Execution Context | Config, limits, callbacks |\n",
    "\n",
    "---\n",
    "\n",
    "### **(c) Execution Loop**\n",
    "\n",
    "The engine repeatedly performs:\n",
    "\n",
    "1. **Select next node**\n",
    "2. **Load state**\n",
    "3. **Execute node function**\n",
    "4. **Merge partial updates**\n",
    "5. **Checkpoint**\n",
    "6. **Evaluate outgoing edges**\n",
    "7. **Schedule next node**\n",
    "\n",
    "This continues until **END** is reached.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Node Scheduling & Control Flow**\n",
    "\n",
    "The engine resolves:\n",
    "\n",
    "```text\n",
    "Which node runs next?\n",
    "```\n",
    "\n",
    "Using:\n",
    "\n",
    "* Edge definitions\n",
    "* Conditional routers\n",
    "* State values\n",
    "* Concurrency constraints\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    lambda s: \"search\" if s[\"need_search\"] else \"final\",\n",
    "    {\"search\": \"search_node\", \"final\": \"answer_node\"}\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. State Handling & Reducers**\n",
    "\n",
    "Nodes return **partial state updates**:\n",
    "\n",
    "```python\n",
    "def node(state):\n",
    "    return {\"count\": state[\"count\"] + 1}\n",
    "```\n",
    "\n",
    "The engine:\n",
    "\n",
    "1. Applies **reducers**\n",
    "2. Produces new versioned state\n",
    "3. Writes checkpoint\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Concurrency & Parallelism**\n",
    "\n",
    "Independent nodes execute in parallel when possible.\n",
    "\n",
    "| Feature      | Benefit          |\n",
    "| ------------ | ---------------- |\n",
    "| Async nodes  | High throughput  |\n",
    "| Fan-out      | Parallel tasks   |\n",
    "| Fan-in       | Merge results    |\n",
    "| Backpressure | Prevent overload |\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Fault Tolerance & Recovery**\n",
    "\n",
    "| Mechanism        | Function                  |\n",
    "| ---------------- | ------------------------- |\n",
    "| Retry policy     | Handle transient failures |\n",
    "| Timeouts         | Prevent deadlock          |\n",
    "| Checkpointing    | Resume after crash        |\n",
    "| Idempotency      | Safe re-execution         |\n",
    "| Circuit breakers | Prevent cascading failure |\n",
    "\n",
    "```python\n",
    "graph.invoke(state, config={\"recursion_limit\": 20})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Human-in-the-Loop Support**\n",
    "\n",
    "Execution engine supports:\n",
    "\n",
    "* Interrupts\n",
    "* Approval gates\n",
    "* Manual state edits\n",
    "* Step-through execution\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Observability & Tracing**\n",
    "\n",
    "Integrated with:\n",
    "\n",
    "* LangSmith\n",
    "* OpenTelemetry\n",
    "* Logging & metrics systems\n",
    "\n",
    "Produces:\n",
    "\n",
    "* Node timing\n",
    "* State diffs\n",
    "* Cost & production telemetry\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Why LangGraph’s Execution Engine Matters**\n",
    "\n",
    "Without it, LLM workflows are:\n",
    "\n",
    "* Fragile\n",
    "* Non-recoverable\n",
    "* Non-scalable\n",
    "\n",
    "With it, they become:\n",
    "\n",
    "* **Persistent**\n",
    "* **Fault-tolerant**\n",
    "* **Observable**\n",
    "* **Autonomous**\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Mental Model**\n",
    "\n",
    "LangGraph’s execution engine behaves like a **distributed operating system for LLM workflows**:\n",
    "\n",
    "> It schedules work, manages memory, enforces safety, and guarantees progress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    value: int\n",
    "    done: bool\n",
    "\n",
    "def increment_node(state: State):\n",
    "    print(f\"INCREMENT: {state['value']} → {state['value'] + 1}\")\n",
    "    return {\"value\": state[\"value\"] + 1}\n",
    "\n",
    "def check_node(state: State):\n",
    "    finished = state[\"value\"] >= 5\n",
    "    print(f\"CHECK: {state['value']}  done={finished}\")\n",
    "    return {\"done\": finished}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"inc\", increment_node)\n",
    "builder.add_node(\"check\", check_node)\n",
    "\n",
    "builder.set_entry_point(\"inc\")\n",
    "builder.add_edge(\"inc\", \"check\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"check\",\n",
    "    lambda s: END if s[\"done\"] else \"inc\",\n",
    "    {\"inc\": \"inc\", END: END}\n",
    ")\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCREMENT: 0 → 1\n",
      "CHECK: 1  done=False\n",
      "INCREMENT: 1 → 2\n",
      "CHECK: 2  done=False\n",
      "INCREMENT: 2 → 3\n",
      "CHECK: 3  done=False\n",
      "INCREMENT: 3 → 4\n",
      "CHECK: 4  done=False\n",
      "INCREMENT: 4 → 5\n",
      "CHECK: 5  done=True\n",
      "\n",
      "FINAL STATE: {'value': 5, 'done': True}\n"
     ]
    }
   ],
   "source": [
    "final_state = graph.invoke({\"value\": 0, \"done\": False})\n",
    "print(\"\\nFINAL STATE:\", final_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
