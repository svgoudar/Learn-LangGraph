{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Thread ID\n",
    "\n",
    "In LangGraph, a **Thread ID** is the fundamental identifier that represents a **single continuous execution context** of a graph over time.\n",
    "It enables **state persistence, memory continuity, resumability, concurrency isolation, and multi-user scaling**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Intuition**\n",
    "\n",
    "Without Thread IDs, every graph invocation would be **stateless** and independent.\n",
    "\n",
    "With Thread IDs, LangGraph becomes a **long-running, stateful system**.\n",
    "\n",
    "> **Thread ID = the identity of a conversation / workflow / agent instance**\n",
    "\n",
    "Each Thread ID owns:\n",
    "\n",
    "* its **state**\n",
    "* its **memory**\n",
    "* its **checkpoints**\n",
    "* its **execution history**\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Why Thread ID Exists**\n",
    "\n",
    "| Problem           | Without Thread ID | With Thread ID |\n",
    "| ----------------- | ----------------- | -------------- |\n",
    "| State continuity  | Lost              | Preserved      |\n",
    "| Multi-turn agents | Impossible        | Native         |\n",
    "| Parallel users    | Collisions        | Isolated       |\n",
    "| Crash recovery    | No                | Yes            |\n",
    "| Human-in-loop     | Hard              | Natural        |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Thread ID Lifecycle**\n",
    "\n",
    "```\n",
    "Client Request\n",
    "     ↓\n",
    "Thread ID Created / Retrieved\n",
    "     ↓\n",
    "Graph Executes on Thread\n",
    "     ↓\n",
    "State Checkpointed\n",
    "     ↓\n",
    "Execution Paused / Continued Later\n",
    "```\n",
    "\n",
    "The same Thread ID can live for **minutes, days, or months**.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Formal Definition**\n",
    "\n",
    "> A Thread ID is a **unique key** that maps to a **persistent state machine instance** of a compiled LangGraph.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. How Thread ID Works Internally**\n",
    "\n",
    "For each Thread ID, LangGraph maintains:\n",
    "\n",
    "| Component        | Description                |\n",
    "| ---------------- | -------------------------- |\n",
    "| State Store      | Current shared state       |\n",
    "| Checkpoint Store | Historical snapshots       |\n",
    "| Execution Cursor | Where the graph paused     |\n",
    "| Message History  | Conversation memory        |\n",
    "| Metadata         | User, timestamps, policies |\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Using Thread ID in Code**\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"user_42_chat\"\n",
    "    }\n",
    "}\n",
    "\n",
    "result1 = graph.invoke({\"input\": \"Hello\"}, config=config)\n",
    "result2 = graph.invoke({\"input\": \"Continue\"}, config=config)\n",
    "```\n",
    "\n",
    "Both calls operate on **the same evolving state**.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Thread ID vs Stateless Invocation**\n",
    "\n",
    "| Feature                  | Stateless | With Thread ID |\n",
    "| ------------------------ | --------- | -------------- |\n",
    "| Memory                   | ❌         | ✅              |\n",
    "| Multi-turn dialogue      | ❌         | ✅              |\n",
    "| Recovery after crash     | ❌         | ✅              |\n",
    "| Long workflows           | ❌         | ✅              |\n",
    "| Human approval workflows | ❌         | ✅              |\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Thread ID and Checkpointing**\n",
    "\n",
    "Every step of execution is checkpointed:\n",
    "\n",
    "```python\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "```\n",
    "\n",
    "This allows:\n",
    "\n",
    "* resume after crash\n",
    "* replay from any step\n",
    "* time travel debugging\n",
    "\n",
    "All scoped by **Thread ID**.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Production Use Cases**\n",
    "\n",
    "| Use Case          | How Thread ID Is Used           |\n",
    "| ----------------- | ------------------------------- |\n",
    "| Chatbots          | One Thread per conversation     |\n",
    "| Agents            | One Thread per agent instance   |\n",
    "| Workflows         | One Thread per business process |\n",
    "| Human review      | One Thread per case             |\n",
    "| Multi-tenant apps | One Thread per user/session     |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Thread ID in Distributed Systems**\n",
    "\n",
    "In production:\n",
    "\n",
    "```\n",
    "User → API → Thread ID → LangGraph Cluster\n",
    "```\n",
    "\n",
    "Thread ID becomes the **routing key** for:\n",
    "\n",
    "* load balancing\n",
    "* state retrieval\n",
    "* execution continuation\n",
    "* fault recovery\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Common Pitfalls**\n",
    "\n",
    "| Mistake                    | Consequence   |\n",
    "| -------------------------- | ------------- |\n",
    "| Reusing Thread IDs         | Data leakage  |\n",
    "| Not persisting checkpoints | Lost memory   |\n",
    "| Stateless configs          | No continuity |\n",
    "| Unbounded thread growth    | Memory leak   |\n",
    "\n",
    "---\n",
    "\n",
    "### **12. Mental Model**\n",
    "\n",
    "Think of a Thread ID as:\n",
    "\n",
    "> **A database primary key for a living AI workflow**\n",
    "\n",
    "Each thread is a **mini operating system process** for your agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[str], add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: State):\n",
    "    user_msg = state[\"messages\"][-1]\n",
    "    return {\n",
    "        \"messages\": [f\"Assistant: I received -> {user_msg}\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chat\", chat_node)\n",
    "builder.set_entry_point(\"chat\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='3c1fed5c-8896-4e4a-b340-08af65ad0eef'), HumanMessage(content=\"Assistant: I received -> content='Hello' additional_kwargs={} response_metadata={} id='3c1fed5c-8896-4e4a-b340-08af65ad0eef'\", additional_kwargs={}, response_metadata={}, id='a60396dd-d046-4512-ac8f-3acd8b91b3d1'), HumanMessage(content='How are you?', additional_kwargs={}, response_metadata={}, id='66bb0ec9-a5c6-40c8-9ff9-11e2007b02d8'), HumanMessage(content=\"Assistant: I received -> content='How are you?' additional_kwargs={} response_metadata={} id='66bb0ec9-a5c6-40c8-9ff9-11e2007b02d8'\", additional_kwargs={}, response_metadata={}, id='fe38a5c3-9741-48c8-bd09-1ee0c4ea28f7')]}\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"conversation_001\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# First message\n",
    "out1 = graph.invoke({\"messages\": [\"Hello\"]}, config=config)\n",
    "# print(out1)\n",
    "\n",
    "# Second message, same Thread ID\n",
    "out2 = graph.invoke({\"messages\": [\"How are you?\"]}, config=config)\n",
    "print(out2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_value = memory.get(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='3c1fed5c-8896-4e4a-b340-08af65ad0eef'),\n",
       " HumanMessage(content=\"Assistant: I received -> content='Hello' additional_kwargs={} response_metadata={} id='3c1fed5c-8896-4e4a-b340-08af65ad0eef'\", additional_kwargs={}, response_metadata={}, id='a60396dd-d046-4512-ac8f-3acd8b91b3d1'),\n",
       " HumanMessage(content='How are you?', additional_kwargs={}, response_metadata={}, id='66bb0ec9-a5c6-40c8-9ff9-11e2007b02d8'),\n",
       " HumanMessage(content=\"Assistant: I received -> content='How are you?' additional_kwargs={} response_metadata={} id='66bb0ec9-a5c6-40c8-9ff9-11e2007b02d8'\", additional_kwargs={}, response_metadata={}, id='fe38a5c3-9741-48c8-bd09-1ee0c4ea28f7')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_value[\"channel_values\"]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
