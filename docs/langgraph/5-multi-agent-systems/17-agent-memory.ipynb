{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e287382",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## **Agent Memory in LangGraph**\n",
    "\n",
    "**Agent Memory** in LangGraph is the collection of mechanisms that allow an agent to **store, retrieve, update, and reason over information across time and executions**.\n",
    "It enables **learning, long-horizon reasoning, personalization, and continuity**—all of which are impossible in stateless pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Why Agent Memory Is Necessary**\n",
    "\n",
    "Without memory, an agent behaves like a **single-turn function**.\n",
    "With memory, it becomes a **persistent intelligent system**.\n",
    "\n",
    "| Capability             | Without Memory | With Memory  |\n",
    "| ---------------------- | -------------- | ------------ |\n",
    "| Context retention      | No             | Yes          |\n",
    "| Multi-step planning    | Limited        | Long-horizon |\n",
    "| Personalization        | None           | Persistent   |\n",
    "| Learning from mistakes | No             | Yes          |\n",
    "| Autonomous behavior    | Fragile        | Robust       |\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Memory Layers in LangGraph**\n",
    "\n",
    "LangGraph implements memory as a **multi-layer architecture**.\n",
    "\n",
    "```\n",
    "┌───────────────────────────────┐\n",
    "│   Long-Term Memory (Vector DB)│\n",
    "├───────────────────────────────┤\n",
    "│   Short-Term Memory (State)   │\n",
    "├───────────────────────────────┤\n",
    "│   Working Memory (Messages)   │\n",
    "└───────────────────────────────┘\n",
    "```\n",
    "\n",
    "| Layer             | Purpose                   | Lifetime    |\n",
    "| ----------------- | ------------------------- | ----------- |\n",
    "| Working Memory    | Current reasoning context | One step    |\n",
    "| Short-Term Memory | Graph state               | One run     |\n",
    "| Long-Term Memory  | Persistent knowledge      | Across runs |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Memory Types**\n",
    "\n",
    "| Type                  | Implementation             |\n",
    "| --------------------- | -------------------------- |\n",
    "| **Working Memory**    | `messages` in state        |\n",
    "| **Short-Term Memory** | State fields in graph      |\n",
    "| **Episodic Memory**   | Checkpoints                |\n",
    "| **Semantic Memory**   | Vector store               |\n",
    "| **Procedural Memory** | Graph structure + policies |\n",
    "| **Tool Memory**       | Tool outputs               |\n",
    "| **User Memory**       | Profile stored in DB       |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Implementing Memory: Core Pattern**\n",
    "\n",
    "#### **State Definition**\n",
    "\n",
    "```python\n",
    "class AgentState(TypedDict):\n",
    "    messages: list\n",
    "    user_profile: dict\n",
    "    task_memory: list\n",
    "```\n",
    "\n",
    "This state becomes the agent’s **short-term memory**.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Long-Term Memory with Vector Store**\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "memory_store = FAISS.from_texts([], OpenAIEmbeddings())\n",
    "```\n",
    "\n",
    "#### **Writing to Memory**\n",
    "\n",
    "```python\n",
    "def store_memory(state):\n",
    "    memory_store.add_texts([state[\"messages\"][-1][\"content\"]])\n",
    "    return {}\n",
    "```\n",
    "\n",
    "#### **Retrieving from Memory**\n",
    "\n",
    "```python\n",
    "def retrieve_memory(state):\n",
    "    docs = memory_store.similarity_search(state[\"messages\"][-1][\"content\"], k=3)\n",
    "    return {\"long_term_context\": [d.page_content for d in docs]}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Memory-Augmented Agent Loop**\n",
    "\n",
    "```\n",
    "User Input\n",
    "   ↓\n",
    "Retrieve Memory\n",
    "   ↓\n",
    "Reason (LLM)\n",
    "   ↓\n",
    "Act (Tools)\n",
    "   ↓\n",
    "Store Experience\n",
    "   ↓\n",
    "Update State\n",
    "   ↓\n",
    "Repeat\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Checkpointing: Episodic Memory**\n",
    "\n",
    "LangGraph supports persistent execution memory:\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint import SqliteSaver\n",
    "\n",
    "checkpointer = SqliteSaver(\"agent.db\")\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "```\n",
    "\n",
    "This allows:\n",
    "\n",
    "* Resume after crash\n",
    "* Replay execution\n",
    "* Inspect historical states\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Agent Memory in Multi-Agent Systems**\n",
    "\n",
    "| Memory Scope  | Usage                    |\n",
    "| ------------- | ------------------------ |\n",
    "| Agent-local   | Individual learning      |\n",
    "| Shared memory | Team coordination        |\n",
    "| Global memory | Organizational knowledge |\n",
    "\n",
    "Agents communicate through **shared memory fields** in state.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Production Memory Architecture**\n",
    "\n",
    "```\n",
    "LangGraph\n",
    "   |\n",
    "State Store (Redis)\n",
    "   |\n",
    "Vector DB (Pinecone / FAISS / Weaviate)\n",
    "   |\n",
    "Relational DB (Postgres)\n",
    "```\n",
    "\n",
    "| Component        | Stores                |\n",
    "| ---------------- | --------------------- |\n",
    "| Redis            | Short-term state      |\n",
    "| Vector DB        | Semantic memory       |\n",
    "| Postgres         | User & session memory |\n",
    "| Checkpoint store | Execution history     |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Design Best Practices**\n",
    "\n",
    "* Separate **working memory** from **long-term memory**\n",
    "* Limit context size with retrieval + summarization\n",
    "* Use memory decay & pruning\n",
    "* Encrypt sensitive memory\n",
    "* Version memory schema\n",
    "* Add human review for memory writes\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Why Memory Makes Agents Intelligent**\n",
    "\n",
    "| Property        | Explanation           |\n",
    "| --------------- | --------------------- |\n",
    "| Continuity      | Understands past      |\n",
    "| Learning        | Improves over time    |\n",
    "| Personalization | Adapts to user        |\n",
    "| Autonomy        | Handles long goals    |\n",
    "| Resilience      | Recovers from failure |\n",
    "\n",
    "---\n",
    "\n",
    "### **Mental Model**\n",
    "\n",
    "> **Memory is the agent’s mind.\n",
    "> LangGraph provides the brain structure that manages it.**\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538f5391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Agent Memory Demo ===\n",
      "\n",
      "--- Interaction 1 ---\n",
      "Retrieved 1 memories\n",
      "Stored memory: User: My name is Sanjeev and I like machine learning.\n",
      "Assistant: Hi Sanjeev! It's great to see you a...\n",
      "Agent: Hi Sanjeev! It's great to see you again. Since you like machine learning, is there a particular area or project you're currently working on or interested in?\n",
      "\n",
      "--- Interaction 2 ---\n",
      "Retrieved 2 memories\n",
      "Stored memory: User: What do I like?\n",
      "Assistant: You like machine learning! Is there a specific aspect of it that yo...\n",
      "Agent: You like machine learning! Is there a specific aspect of it that you're currently exploring or any projects you're working on?\n",
      "\n",
      "--- Interaction 3 ---\n",
      "Retrieved 2 memories\n",
      "Stored memory: User: What's my name?\n",
      "Assistant: Your name is Sanjeev! It's nice to chat with you again. How have yo...\n",
      "Agent: Your name is Sanjeev! It's nice to chat with you again. How have you been?\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# AGENT MEMORY DEMONSTRATION\n",
    "# ============================\n",
    "\n",
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# ---------- Long-Term Memory (Vector DB) ----------\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# Initialize with a dummy document to avoid empty list error\n",
    "vector_store = FAISS.from_texts([\"System initialized\"], embeddings)\n",
    "\n",
    "# ---------- Agent State ----------\n",
    "class AgentState(TypedDict):\n",
    "    messages: List\n",
    "    long_term_context: List[str]\n",
    "\n",
    "# ---------- Nodes ----------\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def retrieve_memory(state: AgentState):\n",
    "    \"\"\"Retrieve relevant memories from vector store.\"\"\"\n",
    "    if not state[\"messages\"]:\n",
    "        return {\"long_term_context\": []}\n",
    "    \n",
    "    # Get the last user message\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    query = last_message.content if hasattr(last_message, 'content') else str(last_message)\n",
    "    \n",
    "    # Search for relevant memories\n",
    "    docs = vector_store.similarity_search(query, k=2)\n",
    "    context = [d.page_content for d in docs] if docs else []\n",
    "    \n",
    "    print(f\"Retrieved {len(context)} memories\")\n",
    "    return {\"long_term_context\": context}\n",
    "\n",
    "def agent_reason(state: AgentState):\n",
    "    \"\"\"Agent reasons using current input and long-term memory.\"\"\"\n",
    "    context = \"\\n\".join(state[\"long_term_context\"]) if state[\"long_term_context\"] else \"No prior memory\"\n",
    "    \n",
    "    last_message = state[\"messages\"][-1]\n",
    "    user_query = last_message.content if hasattr(last_message, 'content') else str(last_message)\n",
    "    \n",
    "    prompt = f\"\"\"You are a helpful assistant with memory.\n",
    "\n",
    "Relevant past memories:\n",
    "{context}\n",
    "\n",
    "User: {user_query}\n",
    "\n",
    "Respond naturally using both current input and past memories when relevant.\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": state[\"messages\"] + [AIMessage(content=response.content)]}\n",
    "\n",
    "def store_memory(state: AgentState):\n",
    "    \"\"\"Store important information to long-term memory.\"\"\"\n",
    "    if len(state[\"messages\"]) >= 2:\n",
    "        # Store both user message and AI response as context\n",
    "        last_user_msg = state[\"messages\"][-2]\n",
    "        last_ai_msg = state[\"messages\"][-1]\n",
    "        \n",
    "        user_content = last_user_msg.content if hasattr(last_user_msg, 'content') else str(last_user_msg)\n",
    "        ai_content = last_ai_msg.content if hasattr(last_ai_msg, 'content') else str(last_ai_msg)\n",
    "        \n",
    "        memory_entry = f\"User: {user_content}\\nAssistant: {ai_content}\"\n",
    "        vector_store.add_texts([memory_entry])\n",
    "        print(f\"Stored memory: {memory_entry[:100]}...\")\n",
    "    \n",
    "    return {}\n",
    "\n",
    "# ---------- Build Graph ----------\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"retrieve\", retrieve_memory)\n",
    "builder.add_node(\"reason\", agent_reason)\n",
    "builder.add_node(\"store\", store_memory)\n",
    "\n",
    "builder.set_entry_point(\"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"reason\")\n",
    "builder.add_edge(\"reason\", \"store\")\n",
    "builder.add_edge(\"store\", END)\n",
    "\n",
    "# ---------- Checkpointing (Episodic Memory) ----------\n",
    "checkpointer = MemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "# ---------- Run ----------\n",
    "print(\"=== Agent Memory Demo ===\\n\")\n",
    "\n",
    "thread_config = {\"configurable\": {\"thread_id\": \"demo-user-123\"}}\n",
    "\n",
    "# First interaction - store information\n",
    "print(\"--- Interaction 1 ---\")\n",
    "result1 = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"My name is Sanjeev and I like machine learning.\")], \n",
    "     \"long_term_context\": []},\n",
    "    thread_config\n",
    ")\n",
    "print(f\"Agent: {result1['messages'][-1].content}\\n\")\n",
    "\n",
    "# Second interaction - recall information\n",
    "print(\"--- Interaction 2 ---\")\n",
    "result2 = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What do I like?\")], \n",
    "     \"long_term_context\": []},\n",
    "    thread_config\n",
    ")\n",
    "print(f\"Agent: {result2['messages'][-1].content}\\n\")\n",
    "\n",
    "# Third interaction - recall name\n",
    "print(\"--- Interaction 3 ---\")\n",
    "result3 = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What's my name?\")], \n",
    "     \"long_term_context\": []},\n",
    "    thread_config\n",
    ")\n",
    "print(f\"Agent: {result3['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8806cee-4bff-4f41-94d5-a0b4b342bfb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "py312env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
