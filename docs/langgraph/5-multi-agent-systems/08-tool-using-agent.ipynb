{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "589d6643",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## **Tool-Using Agent in LangGraph**\n",
    "\n",
    "A **Tool-Using Agent** in LangGraph is an autonomous execution unit that **reasons about a task, selects external tools, invokes them, observes their outputs, and iterates until a goal is achieved** — all within a **stateful, cyclic graph**.\n",
    "\n",
    "It operationalizes the classical **ReAct (Reason → Act → Observe)** paradigm.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Why Tool-Using Agents Exist**\n",
    "\n",
    "LLMs alone cannot:\n",
    "\n",
    "* access real-time data\n",
    "* perform reliable computation\n",
    "* modify external systems\n",
    "* retrieve private knowledge\n",
    "\n",
    "Tool-using agents extend LLMs with **action capability**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Conceptual Workflow**\n",
    "\n",
    "```\n",
    "User Goal\n",
    "   ↓\n",
    "Reason (LLM)\n",
    "   ↓\n",
    "Select Tool\n",
    "   ↓\n",
    "Execute Tool\n",
    "   ↓\n",
    "Observe Result\n",
    "   ↓\n",
    "Update State\n",
    "   ↓\n",
    "Repeat or Finish\n",
    "```\n",
    "\n",
    "This forms a **cyclic LangGraph**.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Core Components in LangGraph**\n",
    "\n",
    "| Component   | Role                        |\n",
    "| ----------- | --------------------------- |\n",
    "| State       | Shared memory between steps |\n",
    "| Reason Node | LLM decides next action     |\n",
    "| Tool Node   | Executes selected tool      |\n",
    "| Router      | Controls loop continuation  |\n",
    "| Termination | Stop condition              |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. State Design**\n",
    "\n",
    "```python\n",
    "class AgentState(TypedDict):\n",
    "    messages: list\n",
    "    tool_result: str\n",
    "    done: bool\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Building a Tool-Using Agent**\n",
    "\n",
    "### Step 1 — Define Tools\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    return f\"Search results for {query}\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2 — Reasoning Node (LLM)\n",
    "\n",
    "```python\n",
    "def reason(state):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": state[\"messages\"] + [response]}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3 — Tool Execution Node\n",
    "\n",
    "```python\n",
    "def act(state):\n",
    "    tool_call = state[\"messages\"][-1].tool_calls[0]\n",
    "    result = tools[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "    return {\"tool_result\": result}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4 — Observation Node\n",
    "\n",
    "```python\n",
    "def observe(state):\n",
    "    state[\"messages\"].append({\"role\": \"tool\", \"content\": state[\"tool_result\"]})\n",
    "    return {}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5 — Loop Control\n",
    "\n",
    "```python\n",
    "def route(state):\n",
    "    if \"FINAL ANSWER\" in state[\"messages\"][-1].content:\n",
    "        return END\n",
    "    return \"reason\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 6 — Assemble Graph\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"reason\", reason)\n",
    "builder.add_node(\"act\", act)\n",
    "builder.add_node(\"observe\", observe)\n",
    "\n",
    "builder.set_entry_point(\"reason\")\n",
    "builder.add_edge(\"reason\", \"act\")\n",
    "builder.add_edge(\"act\", \"observe\")\n",
    "\n",
    "builder.add_conditional_edges(\"observe\", route, {\n",
    "    \"reason\": \"reason\",\n",
    "    END: END\n",
    "})\n",
    "\n",
    "agent = builder.compile()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Execution Example**\n",
    "\n",
    "```python\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Find GDP of India\"}], \"done\": False})\n",
    "```\n",
    "\n",
    "The agent will:\n",
    "\n",
    "```\n",
    "Reason → Choose search → Execute → Observe → Reason → Answer → Stop\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Variants of Tool-Using Agents**\n",
    "\n",
    "| Variant                | Purpose                    |\n",
    "| ---------------------- | -------------------------- |\n",
    "| Single-Tool Agent      | One specialized capability |\n",
    "| Multi-Tool Agent       | Choose among many tools    |\n",
    "| Planner-Executor Agent | Plan then act              |\n",
    "| Self-Reflecting Agent  | Evaluate tool output       |\n",
    "| Human-in-Loop Agent    | Requires approval          |\n",
    "| Autonomous Agent       | Long-running execution     |\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Safety & Production Controls**\n",
    "\n",
    "| Control         | Purpose               |\n",
    "| --------------- | --------------------- |\n",
    "| Tool sandboxing | Prevent misuse        |\n",
    "| Cost limits     | Prevent runaway loops |\n",
    "| Recursion limit | Avoid infinite loops  |\n",
    "| Human approval  | High-risk tools       |\n",
    "| Audit logging   | Compliance            |\n",
    "\n",
    "```python\n",
    "agent.invoke(input, config={\"recursion_limit\": 10})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Why LangGraph is Ideal for Tool-Using Agents**\n",
    "\n",
    "LangGraph provides:\n",
    "\n",
    "* explicit state control\n",
    "* deterministic execution\n",
    "* safe cyclic workflows\n",
    "* persistent memory\n",
    "* human oversight\n",
    "\n",
    "This makes tool-using agents **robust, auditable, and production-ready**.\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b39b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tool-Using Agent Execution ===\n",
      "\n",
      "Conversation trace:\n",
      "\n",
      "1. HumanMessage:\n",
      "   What is the GDP of India?\n",
      "\n",
      "2. AIMessage:\n",
      "   Tool calls: [{'name': 'search', 'args': {'query': 'GDP of India 2023'}, 'id': 'call_CW9OuydYJR1Uc0ru0gmSTiZu', 'type': 'tool_call'}]\n",
      "\n",
      "3. ToolMessage:\n",
      "   India's GDP is approximately $3.7 trillion USD (2023)\n",
      "\n",
      "4. AIMessage:\n",
      "   As of 2023, India's GDP is approximately $3.7 trillion USD.\n",
      "\n",
      "============================================================\n",
      "FINAL ANSWER:\n",
      "============================================================\n",
      "As of 2023, India's GDP is approximately $3.7 trillion USD.\n"
     ]
    }
   ],
   "source": [
    "# ---- ONE CELL: Tool-Using Agent with LangGraph ----\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "# -------- 1. Define State --------\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# -------- 2. Define Tool --------\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search tool that returns information about the query.\"\"\"\n",
    "    # Mock implementation - in real scenario, this would call an API\n",
    "    if \"GDP\" in query or \"India\" in query:\n",
    "        return \"India's GDP is approximately $3.7 trillion USD (2023)\"\n",
    "    return f\"Search results for: {query}\"\n",
    "\n",
    "# -------- 3. LLM --------\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).bind_tools([search])\n",
    "\n",
    "# -------- 4. Nodes --------\n",
    "def reason_and_act(state: AgentState):\n",
    "    \"\"\"LLM reasons and decides whether to use tools or provide final answer.\"\"\"\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def execute_tools(state: AgentState):\n",
    "    \"\"\"Execute any tool calls from the last message.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    tool_calls = last_message.tool_calls\n",
    "    \n",
    "    tool_messages = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        \n",
    "        # Execute the tool\n",
    "        if tool_name == \"search\":\n",
    "            result = search.invoke(tool_args)\n",
    "        else:\n",
    "            result = f\"Unknown tool: {tool_name}\"\n",
    "        \n",
    "        # Create tool message\n",
    "        tool_messages.append(\n",
    "            ToolMessage(content=result, tool_call_id=tool_call[\"id\"])\n",
    "        )\n",
    "    \n",
    "    return {\"messages\": tool_messages}\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Determine if we should continue the loop or end.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # If the last message has tool calls, continue to execute them\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # Otherwise, we're done\n",
    "    return END\n",
    "\n",
    "# -------- 5. Build Graph --------\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"agent\", reason_and_act)\n",
    "builder.add_node(\"tools\", execute_tools)\n",
    "\n",
    "builder.set_entry_point(\"agent\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "agent = builder.compile()\n",
    "\n",
    "# -------- 6. Run --------\n",
    "print(\"=== Tool-Using Agent Execution ===\\n\")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What is the GDP of India?\")]\n",
    "})\n",
    "\n",
    "print(\"Conversation trace:\")\n",
    "for i, msg in enumerate(result[\"messages\"], 1):\n",
    "    role = msg.__class__.__name__\n",
    "    content = msg.content if hasattr(msg, 'content') else str(msg)\n",
    "    print(f\"\\n{i}. {role}:\")\n",
    "    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "        print(f\"   Tool calls: {msg.tool_calls}\")\n",
    "    else:\n",
    "        print(f\"   {content[:200]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(\"=\"*60)\n",
    "print(result[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
