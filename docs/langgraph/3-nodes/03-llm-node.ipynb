{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9b0bfe",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## **LLM Node in LangGraph**\n",
    "\n",
    "An **LLM Node** in LangGraph is a specialized **graph node** whose primary responsibility is to perform **language model inference** and write the result into the shared **graph state**.\n",
    "It is the fundamental building block for reasoning, planning, dialogue, and decision-making in LangGraph workflows.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Conceptual Role of an LLM Node**\n",
    "\n",
    "An LLM node transforms **state → text → new state**.\n",
    "\n",
    "```\n",
    "(State) → Prompt Construction → LLM Inference → Parsing → State Update\n",
    "```\n",
    "\n",
    "It behaves like a **pure function over state**, except the computation is delegated to a language model.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Why LLM Nodes Are First-Class in LangGraph**\n",
    "\n",
    "LLM nodes allow the graph to:\n",
    "\n",
    "| Capability | Description               |\n",
    "| ---------- | ------------------------- |\n",
    "| Reason     | Interpret complex inputs  |\n",
    "| Plan       | Decompose tasks           |\n",
    "| Decide     | Choose next actions       |\n",
    "| Generate   | Produce text/code         |\n",
    "| Reflect    | Self-critique and improve |\n",
    "\n",
    "Without LLM nodes, LangGraph would only orchestrate deterministic programs.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Anatomy of an LLM Node**\n",
    "\n",
    "An LLM node consists of:\n",
    "\n",
    "| Component    | Purpose                           |\n",
    "| ------------ | --------------------------------- |\n",
    "| Prompt       | Instructions + context            |\n",
    "| Model        | LLM backend                       |\n",
    "| Parser       | Converts text → structured output |\n",
    "| State Mapper | Writes parsed output into state   |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Basic LLM Node Example**\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def llm_node(state: State):\n",
    "    prompt = f\"Answer this question: {state['question']}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"llm\", llm_node)\n",
    "```\n",
    "\n",
    "The node:\n",
    "\n",
    "1. Reads `state[\"question\"]`\n",
    "2. Calls the LLM\n",
    "3. Writes to `state[\"answer\"]`\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Structured Output with LLM Nodes**\n",
    "\n",
    "For production systems, outputs should be **structured**.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Output(BaseModel):\n",
    "    decision: str\n",
    "    confidence: float\n",
    "\n",
    "def llm_node(state):\n",
    "    response = llm.with_structured_output(Output).invoke(state[\"input\"])\n",
    "    return response.dict()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. LLM Nodes with Tools**\n",
    "\n",
    "LLM nodes may **invoke tools**:\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    ...\n",
    "\n",
    "llm = ChatOpenAI().bind_tools([search])\n",
    "```\n",
    "\n",
    "The node becomes a **controller** that decides when and how tools are used.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. LLM Nodes in Cyclic Graphs**\n",
    "\n",
    "LLM nodes often live inside **loops**:\n",
    "\n",
    "```\n",
    "Reason (LLM) → Act (Tool) → Observe → Reason\n",
    "```\n",
    "\n",
    "This enables:\n",
    "\n",
    "* Self-correction\n",
    "* Planning & replanning\n",
    "* Autonomous behavior\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Variants of LLM Nodes**\n",
    "\n",
    "| Variant         | Purpose               |\n",
    "| --------------- | --------------------- |\n",
    "| Planner Node    | Generates plan        |\n",
    "| Executor Node   | Performs actions      |\n",
    "| Critic Node     | Evaluates output      |\n",
    "| Router Node     | Selects next path     |\n",
    "| Reflection Node | Improves prior result |\n",
    "| Summarizer Node | Compresses context    |\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Reliability & Production Controls**\n",
    "\n",
    "| Feature            | Why                       |\n",
    "| ------------------ | ------------------------- |\n",
    "| Retries            | Handle model failures     |\n",
    "| Timeouts           | Prevent hangs             |\n",
    "| Parsing validation | Prevent malformed output  |\n",
    "| Token limits       | Cost control              |\n",
    "| Caching            | Reduce latency            |\n",
    "| Model routing      | Cost-performance tradeoff |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Mental Model**\n",
    "\n",
    "An LLM node is the **cognitive engine** of the graph.\n",
    "\n",
    "> **State is the memory.\n",
    "> LLM nodes are the brain.\n",
    "> Edges are the nervous system.**\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21cd8817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "import json\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    thoughts: List[str]\n",
    "    answer: str\n",
    "    confidence: float\n",
    "    done: bool\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculator(expr: str) -> str:\n",
    "    \"\"\"A simple calculator that evaluates mathematical expressions.\"\"\"\n",
    "    return str(eval(expr))\n",
    "\n",
    "def reason_node(state: State):\n",
    "    prompt = f\"\"\"\n",
    "Question: {state['question']}\n",
    "Previous thoughts: {state['thoughts']}\n",
    "\n",
    "Think and decide next step.\n",
    "If confident, answer.\n",
    "If calculation required, specify calculation.\n",
    "Return JSON with fields: thought, answer, confidence, done.\n",
    "\"\"\"\n",
    "    response = llm.invoke(prompt).content\n",
    "    # Use json.loads() instead of eval() to properly parse JSON\n",
    "    data = json.loads(response)\n",
    "\n",
    "    return {\n",
    "        \"thoughts\": state[\"thoughts\"] + [data[\"thought\"]],\n",
    "        \"answer\": data[\"answer\"],\n",
    "        \"confidence\": data[\"confidence\"],\n",
    "        \"done\": data[\"done\"]\n",
    "    }\n",
    "\n",
    "def tool_node(state: State):\n",
    "    expr = state[\"thoughts\"][-1]\n",
    "    result = calculator(expr)\n",
    "    return {\"thoughts\": state[\"thoughts\"] + [f\"Result: {result}\"]}\n",
    "\n",
    "from langgraph.graph import END\n",
    "\n",
    "def router(state: State):\n",
    "    if state[\"done\"]:\n",
    "        return END\n",
    "    return \"reason\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae027afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"reason\", reason_node)\n",
    "builder.add_node(\"tool\", tool_node)\n",
    "\n",
    "builder.set_entry_point(\"reason\")\n",
    "\n",
    "builder.add_edge(\"tool\", \"reason\")\n",
    "builder.add_conditional_edges(\"reason\", router, {\n",
    "    \"reason\": \"reason\",\n",
    "    END: END\n",
    "})\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9465530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is (23 * 7) + 15?', 'thoughts': ['First, I need to calculate 23 * 7, and then I will add 15 to the result.'], 'answer': 176, 'confidence': 'high', 'done': True}\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\n",
    "    \"question\": \"What is (23 * 7) + 15?\",\n",
    "    \"thoughts\": [],\n",
    "    \"answer\": \"\",\n",
    "    \"confidence\": 0.0,\n",
    "    \"done\": False\n",
    "})\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1705b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
