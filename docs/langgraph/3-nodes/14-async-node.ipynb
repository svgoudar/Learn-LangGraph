{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc29dbd",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Async Node\n",
    "\n",
    "An **Async Node** in LangGraph is a node whose execution function is declared as `async` and executed within LangGraph’s asynchronous runtime.\n",
    "It enables **non-blocking execution**, **parallel I/O**, and **high-throughput pipelines**, which are essential for production-grade LLM systems.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Motivation: Why Async Nodes Exist**\n",
    "\n",
    "LLM workflows are dominated by **I/O-bound operations**:\n",
    "\n",
    "| Operation        | Nature      |\n",
    "| ---------------- | ----------- |\n",
    "| LLM calls        | Network I/O |\n",
    "| Tool APIs        | Network I/O |\n",
    "| Database queries | I/O         |\n",
    "| Vector search    | I/O         |\n",
    "| File systems     | I/O         |\n",
    "\n",
    "Synchronous execution blocks the runtime and wastes resources.\n",
    "**Async nodes allow concurrency without threads.**\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Conceptual Model**\n",
    "\n",
    "**Synchronous Node**\n",
    "\n",
    "```\n",
    "Node A → wait → Node B → wait → Node C\n",
    "```\n",
    "\n",
    "**Async Node**\n",
    "\n",
    "```\n",
    "Node A ─┬─→ await\n",
    "        ├─→ await\n",
    "        └─→ await\n",
    "```\n",
    "\n",
    "Multiple operations proceed concurrently under one event loop.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Defining an Async Node**\n",
    "\n",
    "An async node is defined using `async def`.\n",
    "\n",
    "```python\n",
    "async def fetch_data(state):\n",
    "    result = await external_api_call(state[\"query\"])\n",
    "    return {\"data\": result}\n",
    "```\n",
    "\n",
    "```python\n",
    "builder.add_node(\"fetch\", fetch_data)\n",
    "```\n",
    "\n",
    "LangGraph automatically detects coroutine functions and schedules them asynchronously.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Minimal Working Example**\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "import asyncio\n",
    "\n",
    "class State(TypedDict):\n",
    "    value: int\n",
    "\n",
    "async def async_increment(state):\n",
    "    await asyncio.sleep(1)\n",
    "    return {\"value\": state[\"value\"] + 1}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"async_inc\", async_increment)\n",
    "builder.set_entry_point(\"async_inc\")\n",
    "builder.add_edge(\"async_inc\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "result = asyncio.run(graph.ainvoke({\"value\": 1}))\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Behavior**\n",
    "\n",
    "* Non-blocking delay\n",
    "* Event loop remains responsive\n",
    "* High scalability\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Parallel Async Execution**\n",
    "\n",
    "Multiple async nodes can run concurrently.\n",
    "\n",
    "```python\n",
    "async def call_api_a(state):\n",
    "    return {\"a\": await api_a()}\n",
    "\n",
    "async def call_api_b(state):\n",
    "    return {\"b\": await api_b()}\n",
    "```\n",
    "\n",
    "```python\n",
    "builder.add_node(\"A\", call_api_a)\n",
    "builder.add_node(\"B\", call_api_b)\n",
    "\n",
    "builder.add_edge(\"start\", \"A\")\n",
    "builder.add_edge(\"start\", \"B\")\n",
    "builder.add_edge(\"A\", \"join\")\n",
    "builder.add_edge(\"B\", \"join\")\n",
    "```\n",
    "\n",
    "Both API calls execute in parallel.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. State Semantics in Async Nodes**\n",
    "\n",
    "LangGraph enforces **deterministic state updates**:\n",
    "\n",
    "| Rule            | Meaning                                |\n",
    "| --------------- | -------------------------------------- |\n",
    "| Isolation       | Each node receives a snapshot of state |\n",
    "| Partial updates | Node returns only modified fields      |\n",
    "| Reducer merge   | Concurrent updates resolved by reducer |\n",
    "\n",
    "This prevents race conditions even under concurrency.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Async vs Sync Nodes**\n",
    "\n",
    "| Feature        | Sync Node | Async Node   |\n",
    "| -------------- | --------- | ------------ |\n",
    "| Execution      | Blocking  | Non-blocking |\n",
    "| Concurrency    | Limited   | High         |\n",
    "| I/O efficiency | Low       | High         |\n",
    "| Scalability    | Moderate  | Excellent    |\n",
    "\n",
    "---\n",
    "\n",
    "### **8. When to Use Async Nodes**\n",
    "\n",
    "Use async nodes when:\n",
    "\n",
    "* Calling LLM APIs\n",
    "* Using vector databases\n",
    "* Calling microservices\n",
    "* Performing file I/O\n",
    "* Running parallel tools\n",
    "\n",
    "Avoid async for pure CPU-heavy computation.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Production Best Practices**\n",
    "\n",
    "| Practice          | Benefit               |\n",
    "| ----------------- | --------------------- |\n",
    "| Use `ainvoke`     | Enables async runtime |\n",
    "| Limit concurrency | Prevent overload      |\n",
    "| Add timeouts      | Avoid hangs           |\n",
    "| Use retries       | Fault tolerance       |\n",
    "| Use semaphores    | Resource control      |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Mental Model**\n",
    "\n",
    "Async nodes transform LangGraph from a **pipeline executor** into an **event-driven workflow engine** capable of serving production-scale LLM systems.\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9db12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "import asyncio\n",
    "\n",
    "class State(TypedDict):\n",
    "    query: str\n",
    "    llm_result: str\n",
    "    db_result: str\n",
    "\n",
    "\n",
    "async def fake_llm_call(query: str):\n",
    "    await asyncio.sleep(2)  # simulate network latency\n",
    "    return f\"LLM answer for: {query}\"\n",
    "\n",
    "async def fake_db_search(query: str):\n",
    "    await asyncio.sleep(2)\n",
    "    return f\"DB result for: {query}\"\n",
    "\n",
    "async def llm_node(state: State):\n",
    "    result = await fake_llm_call(state[\"query\"])\n",
    "    return {\"llm_result\": result}\n",
    "\n",
    "async def db_node(state: State):\n",
    "    result = await fake_db_search(state[\"query\"])\n",
    "    return {\"db_result\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ec2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"llm\", llm_node)\n",
    "builder.add_node(\"db\", db_node)\n",
    "\n",
    "builder.set_entry_point(\"start\")\n",
    "\n",
    "builder.add_node(\"start\", lambda state: state)\n",
    "\n",
    "builder.add_edge(\"start\", \"llm\")\n",
    "builder.add_edge(\"start\", \"db\")\n",
    "\n",
    "builder.add_edge(\"llm\", END)\n",
    "builder.add_edge(\"db\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9f7bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'LangGraph async nodes', 'llm_result': 'LLM answer for: LangGraph async nodes', 'db_result': 'DB result for: LangGraph async nodes'}\n",
      "Elapsed: 2.016120433807373\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result = await graph.ainvoke({\n",
    "    \"query\": \"LangGraph async nodes\"\n",
    "})\n",
    "\n",
    "print(result)\n",
    "print(\"Elapsed:\", time.time() - start_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
