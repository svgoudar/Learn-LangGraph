{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fec4a92-0370-4d6b-8733-c655bf9746ad",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## **Tool Binding in LangGraph**\n",
    "\n",
    "**Tool binding** in LangGraph is the mechanism that allows LLM-driven nodes to **call external tools reliably and deterministically** by exposing tool interfaces to the model and enforcing structured invocation within the graph execution framework.\n",
    "\n",
    "Tool binding is what transforms a language model from a **text generator** into a **capability-driven agent**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Motivation: Why Tool Binding Exists**\n",
    "\n",
    "LLMs alone cannot:\n",
    "\n",
    "* Query databases\n",
    "* Call APIs\n",
    "* Execute code\n",
    "* Read files\n",
    "* Perform transactions\n",
    "\n",
    "Tool binding connects **LLM reasoning** with **real-world actions**.\n",
    "\n",
    "```\n",
    "LLM ──► Decide which tool to call\n",
    "       ▼\n",
    "   Structured Tool Invocation\n",
    "       ▼\n",
    " External System / API / Function\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Core Components of Tool Binding**\n",
    "\n",
    "| Component             | Role                                  |\n",
    "| --------------------- | ------------------------------------- |\n",
    "| Tool Definition       | Declares tool interface               |\n",
    "| Tool Registry         | Stores available tools                |\n",
    "| Tool Schema           | Input/output contract                 |\n",
    "| Tool Executor         | Executes the tool                     |\n",
    "| Tool Node             | LangGraph node that performs the call |\n",
    "| Tool Result Injection | Writes tool output into state         |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Tool Definition**\n",
    "\n",
    "Tools are normal Python functions with a schema.\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search the web for information.\"\"\"\n",
    "    return \"Search result\"\n",
    "```\n",
    "\n",
    "The decorator automatically generates a **JSON schema**.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Binding Tools to an LLM Node**\n",
    "\n",
    "```python\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\").bind_tools([search])\n",
    "```\n",
    "\n",
    "This injects the tool schema into the model's prompt and enables **function calling**.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Tool Node in LangGraph**\n",
    "\n",
    "```python\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_node = ToolNode([search])\n",
    "```\n",
    "\n",
    "The **ToolNode** executes whichever tool the model selects.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Complete Execution Workflow**\n",
    "\n",
    "```\n",
    "User Input\n",
    "   ↓\n",
    "LLM Node (with tools bound)\n",
    "   ↓ decides tool call\n",
    "Structured Tool Call (JSON)\n",
    "   ↓\n",
    "ToolNode executes function\n",
    "   ↓\n",
    "Tool result written into state\n",
    "   ↓\n",
    "LLM continues reasoning\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Minimal Working Example**\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict, List\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: List\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    return a * b\n",
    "\n",
    "llm = ChatOpenAI().bind_tools([multiply])\n",
    "\n",
    "def llm_node(state):\n",
    "    return {\"messages\": state[\"messages\"] + [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"llm\", llm_node)\n",
    "graph.add_node(\"tools\", ToolNode([multiply]))\n",
    "\n",
    "graph.set_entry_point(\"llm\")\n",
    "graph.add_edge(\"llm\", \"tools\")\n",
    "graph.add_edge(\"tools\", \"llm\")\n",
    "graph.add_edge(\"llm\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Tool Selection & Routing**\n",
    "\n",
    "LangGraph ensures:\n",
    "\n",
    "* Tool calls are **validated**\n",
    "* Arguments match schema\n",
    "* Failures are caught\n",
    "* Results are injected into state\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Tool Binding Variants**\n",
    "\n",
    "| Variant              | Description                 |\n",
    "| -------------------- | --------------------------- |\n",
    "| Static Binding       | Fixed tools at compile time |\n",
    "| Dynamic Binding      | Tools chosen at runtime     |\n",
    "| Hierarchical Tools   | Tools calling tools         |\n",
    "| Restricted Tools     | Policy-limited tools        |\n",
    "| Sandboxed Tools      | Security-isolated tools     |\n",
    "| Human-Approved Tools | Requires approval           |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Production Considerations**\n",
    "\n",
    "| Concern       | Handling           |\n",
    "| ------------- | ------------------ |\n",
    "| Security      | Tool sandboxing    |\n",
    "| Reliability   | Retries & timeouts |\n",
    "| Observability | Logging tool calls |\n",
    "| Cost          | Track usage        |\n",
    "| Governance    | Access control     |\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Why Tool Binding Matters**\n",
    "\n",
    "Without tool binding → LLM is a **chatbot**\n",
    "With tool binding → LLM becomes an **autonomous system controller**\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "453b039e-60c1-4ef0-8607-2a9c7b46ab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage : What is 17 multiplied by 23?\n",
      "AIMessage : 17 multiplied by 23 equals 391.\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# ------------------ State ------------------\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "\n",
    "# ------------------ Tool ------------------\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# ------------------ LLM ------------------\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# ------------------ Nodes ------------------\n",
    "\n",
    "def llm_node(state: State):\n",
    "    msg = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": state[\"messages\"] + [msg]}\n",
    "\n",
    "def tool_executor(state: State):\n",
    "    last: AIMessage = state[\"messages\"][-1]\n",
    "    \n",
    "    if not last.tool_calls:\n",
    "        return state\n",
    "\n",
    "    call = last.tool_calls[0]\n",
    "    args = call[\"args\"]\n",
    "    result = multiply.invoke(args)\n",
    "\n",
    "    tool_message = AIMessage(content=str(result))\n",
    "    return {\"messages\": state[\"messages\"] + [tool_message]}\n",
    "\n",
    "# ------------------ Router ------------------\n",
    "\n",
    "def route(state: State):\n",
    "    last = state[\"messages\"][-1]\n",
    "    return \"tool\" if getattr(last, \"tool_calls\", None) else END\n",
    "\n",
    "# ------------------ Graph ------------------\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"llm\", llm_node)\n",
    "builder.add_node(\"tool\", tool_executor)\n",
    "\n",
    "builder.set_entry_point(\"llm\")\n",
    "builder.add_conditional_edges(\"llm\", route, {\"tool\": \"tool\", END: END})\n",
    "builder.add_edge(\"tool\", \"llm\")\n",
    "\n",
    "app = builder.compile()\n",
    "\n",
    "# ------------------ Run ------------------\n",
    "\n",
    "initial_state = {\"messages\": [HumanMessage(\"What is 17 multiplied by 23?\")]}\n",
    "result = app.invoke(initial_state)\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    print(type(m).__name__, \":\", m.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e03a9-684b-481d-85ab-eac9ceb87d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
