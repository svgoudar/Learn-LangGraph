{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57530ae5",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## **External Memory in LangGraph**\n",
    "\n",
    "In LangGraph, **External Memory** refers to any storage system **outside the in-memory execution state** that preserves information **across runs, sessions, users, and time**.\n",
    "It enables **long-term learning, personalization, context retention, and system continuity** for production-grade LLM applications.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Why External Memory Is Required**\n",
    "\n",
    "LLM graphs are inherently **stateless between executions**.\n",
    "Without external memory, every invocation starts from zero.\n",
    "\n",
    "External memory enables:\n",
    "\n",
    "| Capability             | Benefit               |\n",
    "| ---------------------- | --------------------- |\n",
    "| Long-term conversation | Persistent assistants |\n",
    "| Knowledge accumulation | Learning systems      |\n",
    "| User personalization   | Adaptive behavior     |\n",
    "| System recovery        | Fault tolerance       |\n",
    "| Audit & compliance     | Traceability          |\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Position in LangGraph Architecture**\n",
    "\n",
    "```\n",
    "User Request\n",
    "   ↓\n",
    "LangGraph Runtime\n",
    "   ↓\n",
    "In-Memory State  ←→  External Memory Store\n",
    "   ↓\n",
    "Graph Execution\n",
    "```\n",
    "\n",
    "* **State**: Short-term, per-run\n",
    "* **External Memory**: Long-term, cross-run\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Types of External Memory**\n",
    "\n",
    "| Memory Type        | Purpose          | Technology          |\n",
    "| ------------------ | ---------------- | ------------------- |\n",
    "| Checkpoint Store   | Resume execution | Redis, Postgres     |\n",
    "| Conversation Store | Dialogue history | SQL / NoSQL         |\n",
    "| Vector Memory      | Semantic recall  | FAISS, Pinecone     |\n",
    "| Knowledge Store    | Structured facts | SQL                 |\n",
    "| User Profile Store | Preferences      | Key-value DB        |\n",
    "| Audit Logs         | Compliance       | Append-only storage |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. External Memory vs Internal State**\n",
    "\n",
    "| Aspect       | State         | External Memory     |\n",
    "| ------------ | ------------- | ------------------- |\n",
    "| Lifetime     | One execution | Persistent          |\n",
    "| Scope        | Thread        | System-wide         |\n",
    "| Access speed | Very fast     | Slower              |\n",
    "| Cost         | Free          | Storage cost        |\n",
    "| Use case     | Control flow  | Knowledge retention |\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Workflow: Using External Memory**\n",
    "\n",
    "#### **Step 1 — Retrieve Memory**\n",
    "\n",
    "```python\n",
    "def load_memory(state):\n",
    "    past = db.get(state[\"user_id\"])\n",
    "    return {\"history\": past}\n",
    "```\n",
    "\n",
    "#### **Step 2 — Use Memory in Reasoning**\n",
    "\n",
    "```python\n",
    "def reason(state):\n",
    "    context = state[\"history\"] + [state[\"input\"]]\n",
    "    response = llm(context)\n",
    "    return {\"output\": response}\n",
    "```\n",
    "\n",
    "#### **Step 3 — Persist Updated Memory**\n",
    "\n",
    "```python\n",
    "def save_memory(state):\n",
    "    db.set(state[\"user_id\"], state[\"history\"] + [state[\"output\"]])\n",
    "    return {}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Vector-Based External Memory**\n",
    "\n",
    "Used for **semantic recall** instead of raw history.\n",
    "\n",
    "```python\n",
    "docs = vector_store.similarity_search(query, k=3)\n",
    "```\n",
    "\n",
    "Benefits:\n",
    "\n",
    "* Retrieves only **relevant** information\n",
    "* Avoids context window overflow\n",
    "* Supports knowledge grounding\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Production Design Pattern**\n",
    "\n",
    "```\n",
    "Request → Load External Memory → Execute Graph → Update Memory → Respond\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Failure Recovery & Checkpointing**\n",
    "\n",
    "External memory enables:\n",
    "\n",
    "* Resume after crash\n",
    "* Rollback incorrect runs\n",
    "* Replay execution history\n",
    "\n",
    "```python\n",
    "graph.invoke(input, config={\"thread_id\": \"user_123\"})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Security & Governance**\n",
    "\n",
    "| Concern            | Control                  |\n",
    "| ------------------ | ------------------------ |\n",
    "| User isolation     | Separate memory per user |\n",
    "| Encryption         | At-rest & in-transit     |\n",
    "| Retention policies | TTL, pruning             |\n",
    "| Auditability       | Immutable logs           |\n",
    "| Access control     | RBAC                     |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. When to Use External Memory**\n",
    "\n",
    "| Scenario           | Required  |\n",
    "| ------------------ | --------- |\n",
    "| Chatbots           | Yes       |\n",
    "| Agents             | Yes       |\n",
    "| Enterprise systems | Mandatory |\n",
    "| Short scripts      | No        |\n",
    "\n",
    "---\n",
    "\n",
    "### **Mental Model**\n",
    "\n",
    "> **State is the brain's working memory.\n",
    "> External memory is long-term memory.**\n",
    "\n",
    "Together they enable **intelligent, persistent, production-ready LLM systems**.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can next explain:\n",
    "\n",
    "• Memory indexing & retrieval strategies\n",
    "• Memory architectures for multi-agent systems\n",
    "• Scaling external memory to millions of users\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ad1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "\n",
    "class State(TypedDict):\n",
    "    user_id: str\n",
    "    input: str\n",
    "    history: List[str]\n",
    "    output: str\n",
    "\n",
    "import shelve\n",
    "\n",
    "memory = shelve.open(\"memory.db\")\n",
    "\n",
    "def load_memory(user_id):\n",
    "    return memory.get(user_id, [])\n",
    "\n",
    "def save_memory(user_id, history):\n",
    "    memory[user_id] = history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac7bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_node(state):\n",
    "    history = load_memory(state[\"user_id\"])\n",
    "    return {\"history\": history}\n",
    "\n",
    "def reason_node(state):\n",
    "    context = \"\\n\".join(state[\"history\"] + [state[\"input\"]])\n",
    "    response = f\"Assistant remembers: {context}\"\n",
    "    return {\"output\": response}\n",
    "\n",
    "def save_node(state):\n",
    "    new_history = state[\"history\"] + [state[\"input\"], state[\"output\"]]\n",
    "    save_memory(state[\"user_id\"], new_history)\n",
    "    return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d715e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"load\", load_node)\n",
    "builder.add_node(\"reason\", reason_node)\n",
    "builder.add_node(\"save\", save_node)\n",
    "\n",
    "builder.set_entry_point(\"load\")\n",
    "builder.add_edge(\"load\", \"reason\")\n",
    "builder.add_edge(\"reason\", \"save\")\n",
    "builder.add_edge(\"save\", END)\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba3b9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant remembers: My favorite color is blue.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\n",
    "    \"user_id\": \"alice\",\n",
    "    \"input\": \"My favorite color is blue.\"\n",
    "})\n",
    "print(result[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9ada9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant remembers: My favorite color is blue.\n",
      "Assistant remembers: My favorite color is blue.\n",
      "What is my favorite color?\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\n",
    "    \"user_id\": \"alice\",\n",
    "    \"input\": \"What is my favorite color?\"\n",
    "})\n",
    "print(result[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227639e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
