{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406f5e08",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## **Memory Store in LangGraph**\n",
    "\n",
    "In LangGraph, a **Memory Store** is the infrastructure that enables **long-term persistence of state and knowledge across graph executions**, transforming LLM workflows from stateless pipelines into **continuous, evolving intelligent systems**.\n",
    "\n",
    "It provides **durable context**, supports **multi-session reasoning**, and enables **agent learning, recovery, and personalization**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Why Memory Store Exists**\n",
    "\n",
    "Without memory, an LLM system behaves like:\n",
    "\n",
    "> *“Solve the task, forget everything.”*\n",
    "\n",
    "With memory, the system becomes:\n",
    "\n",
    "> *“Learn, remember, adapt, improve.”*\n",
    "\n",
    "| Capability             | Without Memory | With Memory |\n",
    "| ---------------------- | -------------- | ----------- |\n",
    "| User personalization   | ❌              | ✅           |\n",
    "| Long conversations     | ❌              | ✅           |\n",
    "| Autonomous agents      | ❌              | ✅           |\n",
    "| Recovery after failure | ❌              | ✅           |\n",
    "| Incremental learning   | ❌              | ✅           |\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Types of Memory in LangGraph**\n",
    "\n",
    "| Memory Type           | Purpose                      |\n",
    "| --------------------- | ---------------------------- |\n",
    "| **Short-Term Memory** | Current graph state          |\n",
    "| **Thread Memory**     | Conversation/session context |\n",
    "| **Checkpoint Memory** | Execution recovery           |\n",
    "| **Long-Term Memory**  | Durable knowledge store      |\n",
    "| **Agent Memory**      | Agent-specific experience    |\n",
    "| **Vector Memory**     | Semantic knowledge retrieval |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Architecture of Memory Store**\n",
    "\n",
    "```\n",
    "LangGraph Runtime\n",
    "     |\n",
    "Shared State\n",
    "     |\n",
    "Checkpoint Store  ──┐\n",
    "Thread Store       ├─→  Memory Store Layer\n",
    "Long-Term Store    │\n",
    "Vector Store  ─────┘\n",
    "```\n",
    "\n",
    "Memory is **externalized** from execution so that workflows can:\n",
    "\n",
    "* pause\n",
    "* crash\n",
    "* migrate\n",
    "* resume\n",
    "* evolve\n",
    "\n",
    "without losing intelligence.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Core Components**\n",
    "\n",
    "| Component            | Function                       |\n",
    "| -------------------- | ------------------------------ |\n",
    "| **State Store**      | Persists current state         |\n",
    "| **Checkpoint Store** | Saves execution snapshots      |\n",
    "| **Thread Store**     | Maintains conversation history |\n",
    "| **Vector Store**     | Semantic knowledge             |\n",
    "| **Metadata Store**   | Audit, logs, versioning        |\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Creating a Memory Store**\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\"memory.db\")\n",
    "```\n",
    "\n",
    "Attach memory to the graph:\n",
    "\n",
    "```python\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "```\n",
    "\n",
    "Now every execution is **persisted automatically**.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Thread-Based Memory**\n",
    "\n",
    "Each execution thread has isolated memory:\n",
    "\n",
    "```python\n",
    "config = {\"configurable\": {\"thread_id\": \"user-123\"}}\n",
    "graph.invoke(input, config)\n",
    "```\n",
    "\n",
    "This enables:\n",
    "\n",
    "* multi-user systems\n",
    "* personalized assistants\n",
    "* long conversations\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Checkpointing & Recovery**\n",
    "\n",
    "If execution crashes:\n",
    "\n",
    "```python\n",
    "graph.invoke(input, config)\n",
    "```\n",
    "\n",
    "LangGraph resumes from the **last checkpoint**.\n",
    "\n",
    "| Feature        | Benefit          |\n",
    "| -------------- | ---------------- |\n",
    "| Crash recovery | No lost progress |\n",
    "| Replay         | Debugging        |\n",
    "| Rollback       | Error correction |\n",
    "| Auditing       | Compliance       |\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Long-Term Knowledge Memory (Vector Store)**\n",
    "\n",
    "Used for **semantic recall**:\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import FAISS\n",
    "vector_store = FAISS.from_texts(docs, embedding)\n",
    "```\n",
    "\n",
    "Integrated into nodes for retrieval-augmented reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Memory in Autonomous Agents**\n",
    "\n",
    "Agents read and write memory continuously:\n",
    "\n",
    "```\n",
    "Perception → Reasoning → Action → Experience → Memory Update → Next Cycle\n",
    "```\n",
    "\n",
    "This enables:\n",
    "\n",
    "* learning from mistakes\n",
    "* preference adaptation\n",
    "* behavior optimization\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Production-Grade Memory Practices**\n",
    "\n",
    "| Concern       | Solution         |\n",
    "| ------------- | ---------------- |\n",
    "| Scalability   | Redis / Postgres |\n",
    "| Durability    | Cloud DB         |\n",
    "| Privacy       | Encryption       |\n",
    "| Governance    | Access control   |\n",
    "| Cost          | TTL & pruning    |\n",
    "| Observability | Audit logs       |\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Mental Model**\n",
    "\n",
    "> **LangGraph Memory = Brain of the system**\n",
    "> State = Working memory\n",
    "> Checkpoints = Episodic memory\n",
    "> Vector store = Semantic memory\n",
    "\n",
    "---\n",
    "\n",
    "### **12. Minimal Example: Memory in Action**\n",
    "\n",
    "```python\n",
    "result1 = graph.invoke({\"input\": \"Hello\"}, config)\n",
    "result2 = graph.invoke({\"input\": \"What did I say?\"}, config)\n",
    "```\n",
    "\n",
    "The system remembers because **memory persists across runs**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Memory Store elevates LangGraph from a **workflow engine** into a **persistent intelligent system** capable of learning, recovering, and evolving over time.\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d513b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: List[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba97d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "memory = InMemorySaver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "799d3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "def chat_node(state: State):\n",
    "    history = state.get(\"messages\", [])\n",
    "    user_msg = history[-1]\n",
    "    \n",
    "    response = f\"I remember you said: {', '.join(history[:-1])}\"\n",
    "    return {\"messages\": history + [response]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chat\", chat_node)\n",
    "builder.set_entry_point(\"chat\")\n",
    "builder.add_edge(\"chat\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f2e3717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': ['Hello', 'I remember you said: ']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"user-1\"}}\n",
    "graph.invoke({\"messages\": [\"Hello\"]}, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df17c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': ['Hello', 'My name is Sanjeev', 'I remember you said: Hello']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\": [\"Hello\", \"My name is Sanjeev\"]}, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03d5ede5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': ['Hello',\n",
       "  'My name is Sanjeev',\n",
       "  'What is my name?',\n",
       "  'I remember you said: Hello, My name is Sanjeev']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\": [\"Hello\", \"My name is Sanjeev\", \"What is my name?\"]}, config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
