{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9da2454",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## **Local Node State in LangGraph**\n",
    "\n",
    "In LangGraph, **Local Node State** refers to **temporary, node-scoped data** that exists only during the execution of a single node and is **not persisted** into the global shared graph state unless explicitly returned.\n",
    "It enables **clean computation, isolation, performance optimization, and safe intermediate reasoning**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Motivation and Intuition**\n",
    "\n",
    "LangGraph maintains a **global state** shared across all nodes.\n",
    "However, complex nodes often need **private working memory**:\n",
    "\n",
    "| Need                   | Why                          |\n",
    "| ---------------------- | ---------------------------- |\n",
    "| Intermediate variables | Avoid polluting global state |\n",
    "| Scratch computations   | Safer experimentation        |\n",
    "| Temporary caches       | Performance                  |\n",
    "| Sensitive data         | Prevent leakage              |\n",
    "\n",
    "Local node state provides this **private workspace**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Conceptual Model**\n",
    "\n",
    "```\n",
    "Global Graph State  ─────────────┐\n",
    "                                 ↓\n",
    "                           [   Node   ]\n",
    "                          ( Local State )\n",
    "                                 ↓\n",
    "Global Graph State  <─────── returned updates\n",
    "```\n",
    "\n",
    "Only the returned values affect the global state.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. How Local Node State Works**\n",
    "\n",
    "A node function receives:\n",
    "\n",
    "```python\n",
    "def node_fn(global_state):\n",
    "    # local variables = local node state\n",
    "```\n",
    "\n",
    "All Python variables inside the function are **local node state** unless returned.\n",
    "\n",
    "```python\n",
    "def analyze(state):\n",
    "    temp_score = expensive_analysis(state[\"input\"])  # local\n",
    "    intermediate = normalize(temp_score)              # local\n",
    "    \n",
    "    return {\"result\": intermediate}   # only this enters global state\n",
    "```\n",
    "\n",
    "`temp_score` and `intermediate` never leave the node.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Why This Matters**\n",
    "\n",
    "| Property    | Benefit                      |\n",
    "| ----------- | ---------------------------- |\n",
    "| Isolation   | Prevents unintended coupling |\n",
    "| Security    | Sensitive data not persisted |\n",
    "| Efficiency  | Smaller global state         |\n",
    "| Correctness | Avoids state corruption      |\n",
    "| Debugging   | Clear data flow              |\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Local vs Global State**\n",
    "\n",
    "| Feature     | Local Node State      | Global State    |\n",
    "| ----------- | --------------------- | --------------- |\n",
    "| Scope       | Single node execution | Entire graph    |\n",
    "| Lifetime    | One execution step    | Whole run       |\n",
    "| Persistence | Not persisted         | Checkpointed    |\n",
    "| Visibility  | Node only             | All nodes       |\n",
    "| Safety      | High                  | Must be managed |\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Example: Clean Multi-Step Node**\n",
    "\n",
    "```python\n",
    "def planner(state):\n",
    "    prompt = build_prompt(state[\"goal\"])      # local\n",
    "    raw_plan = llm(prompt)                    # local\n",
    "    structured = parse_plan(raw_plan)         # local\n",
    "    \n",
    "    return {\"plan\": structured}               # only plan persists\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Performance Optimization with Local State**\n",
    "\n",
    "Expensive objects should remain local:\n",
    "\n",
    "```python\n",
    "def tool_node(state):\n",
    "    model = load_large_model()   # local, not persisted\n",
    "    output = model.run(state[\"data\"])\n",
    "    return {\"tool_result\": output}\n",
    "```\n",
    "\n",
    "This avoids bloating checkpoints.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Local State in Cycles & Agents**\n",
    "\n",
    "In loops and multi-agent systems:\n",
    "\n",
    "* Local state handles **thinking**\n",
    "* Global state handles **memory**\n",
    "\n",
    "This separation prevents **memory explosion** and enables long-running agents.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Anti-Patterns to Avoid**\n",
    "\n",
    "| Anti-Pattern              | Why Bad           |\n",
    "| ------------------------- | ----------------- |\n",
    "| Returning everything      | Bloats state      |\n",
    "| Storing raw LLM outputs   | Noisy memory      |\n",
    "| Persisting temporary data | Slows checkpoints |\n",
    "| Sharing sensitive data    | Security risk     |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Mental Model**\n",
    "\n",
    "> **Local Node State = CPU registers**\n",
    "> **Global State = RAM**\n",
    "\n",
    "Only what must persist should be written to global memory.\n",
    "\n",
    "---\n",
    "\n",
    "### **11. When to Use Local Node State**\n",
    "\n",
    "Use local state for:\n",
    "\n",
    "* Intermediate reasoning\n",
    "* Parsing & normalization\n",
    "* Temporary caches\n",
    "* Tool setup objects\n",
    "* Scratchpad thinking\n",
    "\n",
    "Use global state for:\n",
    "\n",
    "* Decisions\n",
    "* Plans\n",
    "* Results\n",
    "* Long-term memory\n",
    "\n",
    "---\n",
    "\n",
    "### **12. Key Design Principle**\n",
    "\n",
    "> **Persist only what future nodes must know.**\n",
    "\n",
    "This single rule yields **fast, safe, scalable LangGraph systems**.\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e32365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "class State(TypedDict):\n",
    "    user_query: str\n",
    "    decision: str\n",
    "\n",
    "def analyze(state: State):\n",
    "    # -------- Local Node State --------\n",
    "    tokens = state[\"user_query\"].split()         # local\n",
    "    complexity = len(tokens)                     # local\n",
    "    importance_score = complexity * 1.7          # local\n",
    "    reasoning_trace = f\"score={importance_score}\"# local\n",
    "    # ---------------------------------\n",
    "\n",
    "    if importance_score > 5:\n",
    "        decision = \"complex\"\n",
    "    else:\n",
    "        decision = \"simple\"\n",
    "\n",
    "    return {\"decision\": decision}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a56312",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"analyze\", analyze)\n",
    "builder.set_entry_point(\"analyze\")\n",
    "builder.add_edge(\"analyze\", END)\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf1745b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_query': 'Explain local node state in langgraph', 'decision': 'complex'}\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"user_query\": \"Explain local node state in langgraph\"})\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
