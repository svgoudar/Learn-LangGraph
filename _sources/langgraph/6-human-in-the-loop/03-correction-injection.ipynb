{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "269dffa5-342e-4b17-834f-1d1c9a1c5a1b",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## **Correction Injection in LangGraph**\n",
    "\n",
    "**Correction Injection** is a human-in-the-loop control mechanism in LangGraph that allows **external agents (typically humans, sometimes automated validators)** to **modify the execution state mid-run** in order to correct, guide, or override the system’s behavior before execution continues.\n",
    "\n",
    "It is one of the most important features for building **safe, reliable, production-grade LLM systems**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Motivation and Intuition**\n",
    "\n",
    "LLM workflows are probabilistic and error-prone:\n",
    "\n",
    "| Failure Type      | Example              |\n",
    "| ----------------- | -------------------- |\n",
    "| Hallucination     | Fabricated facts     |\n",
    "| Reasoning errors  | Invalid conclusions  |\n",
    "| Tool misuse       | Wrong API parameters |\n",
    "| Policy violations | Unsafe content       |\n",
    "| Ambiguous goals   | Poor plan selection  |\n",
    "\n",
    "Instead of restarting the entire workflow, **Correction Injection** enables:\n",
    "\n",
    "> **Targeted repair of the execution state** without discarding previous progress.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Conceptual Model**\n",
    "\n",
    "```\n",
    "LLM → Partial Output → Human Review\n",
    "                    ↓\n",
    "              Inject Correction\n",
    "                    ↓\n",
    "              Continue Execution\n",
    "```\n",
    "\n",
    "This transforms LangGraph from a static automation engine into a **supervised intelligent system**.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Where Correction Injection Lives in LangGraph**\n",
    "\n",
    "Correction Injection operates at the **State Layer**.\n",
    "\n",
    "```\n",
    "Graph Execution\n",
    "      ↓\n",
    " Shared State  ←── Correction Injection\n",
    "      ↓\n",
    " Next Node\n",
    "```\n",
    "\n",
    "The injected correction becomes part of the **authoritative state** and immediately influences downstream decisions.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Core Mechanisms**\n",
    "\n",
    "| Component            | Role                      |\n",
    "| -------------------- | ------------------------- |\n",
    "| Interrupt Node       | Pauses execution          |\n",
    "| State Snapshot       | Exposes full state        |\n",
    "| Correction Interface | Human edits state         |\n",
    "| State Merge          | Integrates correction     |\n",
    "| Resume               | Continues graph execution |\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Minimal Working Example**\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    draft_answer: str\n",
    "    final_answer: str\n",
    "\n",
    "def generate(state):\n",
    "    return {\"draft_answer\": \"Paris is in Germany\"}   # incorrect\n",
    "\n",
    "def finalize(state):\n",
    "    return {\"final_answer\": state[\"draft_answer\"]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"generate\", generate)\n",
    "builder.add_node(\"finalize\", finalize)\n",
    "\n",
    "builder.set_entry_point(\"generate\")\n",
    "builder.add_edge(\"generate\", \"finalize\")\n",
    "builder.add_edge(\"finalize\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# Step 1: run until correction point\n",
    "state = graph.invoke({\"question\": \"Where is Paris?\"})\n",
    "\n",
    "# Step 2: inject correction\n",
    "state[\"draft_answer\"] = \"Paris is in France\"\n",
    "\n",
    "# Step 3: resume\n",
    "result = graph.invoke(state)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. With Explicit Interrupt Node**\n",
    "\n",
    "```python\n",
    "def review(state):\n",
    "    raise Interrupt(state)\n",
    "\n",
    "builder.add_node(\"review\", review)\n",
    "builder.add_edge(\"generate\", \"review\")\n",
    "builder.add_edge(\"review\", \"finalize\")\n",
    "```\n",
    "\n",
    "Execution pauses at `review`, allowing safe correction.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Production Workflow**\n",
    "\n",
    "| Phase     | Description                         |\n",
    "| --------- | ----------------------------------- |\n",
    "| Run       | System produces intermediate result |\n",
    "| Interrupt | Execution halts                     |\n",
    "| Inspect   | Human reviews state                 |\n",
    "| Correct   | Modify fields                       |\n",
    "| Resume    | Continue execution                  |\n",
    "| Audit     | Log correction                      |\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Variants of Correction Injection**\n",
    "\n",
    "| Variant                  | Use Case                    |\n",
    "| ------------------------ | --------------------------- |\n",
    "| Human correction         | Compliance, quality control |\n",
    "| Rule-based correction    | Automated validation        |\n",
    "| Tool-assisted correction | External checkers           |\n",
    "| Multi-agent correction   | Debate / voting             |\n",
    "| Policy correction        | Safety enforcement          |\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Safety & Reliability Benefits**\n",
    "\n",
    "| Benefit           | Impact                      |\n",
    "| ----------------- | --------------------------- |\n",
    "| Error containment | Prevents cascading failures |\n",
    "| Human oversight   | Regulatory compliance       |\n",
    "| Explainability    | Transparent decisions       |\n",
    "| Cost reduction    | Avoids full reruns          |\n",
    "| Trust             | Enterprise adoption         |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Mental Model**\n",
    "\n",
    "Correction Injection turns LangGraph into:\n",
    "\n",
    "> **A controllable intelligent system rather than an uncontrolled generator.**\n",
    "\n",
    "It enables **real-world AI operations** where **humans remain in command of critical decisions**.\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7b40cc-7a11-4d48-9d09-93a8b3989c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- First Run (Will Interrupt) ---\n",
      "\n",
      "LLM produced: Paris is in Germany\n",
      "\n",
      "State before correction: {'question': 'Where is Paris?', 'draft_answer': 'Paris is in Germany', '__interrupt__': [Interrupt(value={'question': 'Where is Paris?', 'draft_answer': 'Paris is in Germany'}, id='53e21a818be5a9f30a0cc7dc80f05736')]}\n",
      "\n",
      "Human injected correction!\n",
      "\n",
      "--- Resuming Execution ---\n",
      "\n",
      "LLM produced: Paris is in Germany\n",
      "\n",
      "Final result: {'question': 'Where is Paris?', 'draft_answer': 'Paris is in Germany', '__interrupt__': [Interrupt(value={'question': 'Where is Paris?', 'draft_answer': 'Paris is in Germany'}, id='035aa3b4101ef7c08eb5d7cca2330e22')]}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Define State\n",
    "# -----------------------------\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    draft_answer: str\n",
    "    final_answer: str\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Nodes\n",
    "# -----------------------------\n",
    "def generate(state: State):\n",
    "    print(\"\\nLLM produced:\", \"Paris is in Germany\")\n",
    "    return {\"draft_answer\": \"Paris is in Germany\"}  # Wrong on purpose\n",
    "\n",
    "def review(state: State):\n",
    "    # Pause execution and expose state for correction\n",
    "    interrupt(state)\n",
    "\n",
    "def finalize(state: State):\n",
    "    return {\"final_answer\": state[\"draft_answer\"]}\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Build Graph\n",
    "# -----------------------------\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"generate\", generate)\n",
    "builder.add_node(\"review\", review)\n",
    "builder.add_node(\"finalize\", finalize)\n",
    "\n",
    "builder.set_entry_point(\"generate\")\n",
    "builder.add_edge(\"generate\", \"review\")\n",
    "builder.add_edge(\"review\", \"finalize\")\n",
    "builder.add_edge(\"finalize\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Run with Correction Injection\n",
    "# -----------------------------\n",
    "print(\"\\n--- First Run (Will Interrupt) ---\")\n",
    "state = graph.invoke({\"question\": \"Where is Paris?\"})\n",
    "\n",
    "print(\"\\nState before correction:\", state)\n",
    "\n",
    "# ---- HUMAN CORRECTION ----\n",
    "state[\"draft_answer\"] = \"Paris is in France\"\n",
    "print(\"\\nHuman injected correction!\")\n",
    "\n",
    "print(\"\\n--- Resuming Execution ---\")\n",
    "result = graph.invoke(state)\n",
    "\n",
    "print(\"\\nFinal result:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f0a71-d54a-4ecf-a5fd-21096bd050b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
