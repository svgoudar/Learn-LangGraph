{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d9529d-0446-4c4a-bcc0-12384ad6aa6b",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Tree of Thought (ToT)\n",
    "\n",
    "The **Tree of Thought (ToT)** framework is an advanced reasoning paradigm that extends Chain-of-Thought by **exploring multiple reasoning branches simultaneously**, evaluating them, and selecting the most promising path.\n",
    "LangGraph provides a natural implementation substrate for ToT because it supports **branching, parallel execution, state evaluation, and pruning**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Motivation: Why Tree of Thought?**\n",
    "\n",
    "Standard prompting and even ReAct-style loops follow a **single reasoning path**, which is brittle for:\n",
    "\n",
    "* complex planning\n",
    "* ambiguous problems\n",
    "* combinatorial search\n",
    "* strategic decision making\n",
    "\n",
    "Tree of Thought instead treats reasoning as a **search problem**.\n",
    "\n",
    "| Method              | Reasoning Strategy                   |\n",
    "| ------------------- | ------------------------------------ |\n",
    "| Chain-of-Thought    | Single linear trace                  |\n",
    "| ReAct               | Linear with tool feedback            |\n",
    "| **Tree of Thought** | **Multi-branch search + evaluation** |\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Core Components of ToT**\n",
    "\n",
    "| Component    | Role                            |\n",
    "| ------------ | ------------------------------- |\n",
    "| Thought Node | A candidate reasoning step      |\n",
    "| State        | Holds current partial solution  |\n",
    "| Expansion    | Generate multiple next thoughts |\n",
    "| Evaluation   | Score each branch               |\n",
    "| Selection    | Choose best branches            |\n",
    "| Pruning      | Drop low-quality branches       |\n",
    "| Termination  | Detect final solution           |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Mapping ToT onto LangGraph**\n",
    "\n",
    "| ToT Concept         | LangGraph Construct |\n",
    "| ------------------- | ------------------- |\n",
    "| Thought Node        | Graph Node          |\n",
    "| Reasoning State     | Shared State        |\n",
    "| Branch Expansion    | Fan-out edges       |\n",
    "| Parallel Evaluation | Parallel nodes      |\n",
    "| Branch Selection    | Conditional routing |\n",
    "| Pruning             | Edge filtering      |\n",
    "| Search Loop         | Cyclic graph        |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Conceptual Execution Flow**\n",
    "\n",
    "```\n",
    "Start\n",
    "  ↓\n",
    "Generate Thoughts\n",
    "  ↓↓↓\n",
    "Branch A   Branch B   Branch C\n",
    "  ↓         ↓         ↓\n",
    "Evaluate A  Evaluate B Evaluate C\n",
    "   \\        |        /\n",
    "       Select Best K\n",
    "            ↓\n",
    "      Expand Again (Loop)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. State Design**\n",
    "\n",
    "```python\n",
    "class State(TypedDict):\n",
    "    problem: str\n",
    "    thoughts: list[str]\n",
    "    scores: dict[str, float]\n",
    "    best: str\n",
    "    depth: int\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Minimal ToT Implementation in LangGraph**\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List, Dict\n",
    "\n",
    "class State(TypedDict):\n",
    "    problem: str\n",
    "    thoughts: List[str]\n",
    "    scores: Dict[str, float]\n",
    "    best: str\n",
    "    depth: int\n",
    "\n",
    "def generate(state):\n",
    "    prompt = f\"Generate 3 next steps to solve: {state['problem']}\"\n",
    "    thoughts = llm.invoke(prompt).content.split(\"\\n\")\n",
    "    return {\"thoughts\": thoughts}\n",
    "\n",
    "def evaluate(state):\n",
    "    scores = {}\n",
    "    for t in state[\"thoughts\"]:\n",
    "        s = llm.invoke(f\"Score this thought 0-10: {t}\").content\n",
    "        scores[t] = float(s)\n",
    "    best = max(scores, key=scores.get)\n",
    "    return {\"scores\": scores, \"best\": best}\n",
    "\n",
    "def check_depth(state):\n",
    "    if state[\"depth\"] >= 3:\n",
    "        return END\n",
    "    return \"generate\"\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"generate\", generate)\n",
    "builder.add_node(\"evaluate\", evaluate)\n",
    "\n",
    "builder.set_entry_point(\"generate\")\n",
    "builder.add_edge(\"generate\", \"evaluate\")\n",
    "builder.add_conditional_edges(\"evaluate\", check_depth, {\n",
    "    \"generate\": \"generate\",\n",
    "    END: END\n",
    "})\n",
    "\n",
    "graph = builder.compile()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Why LangGraph is Ideal for ToT**\n",
    "\n",
    "| Capability          | Needed for ToT    |\n",
    "| ------------------- | ----------------- |\n",
    "| Cyclic execution    | Multi-step search |\n",
    "| Conditional routing | Branch selection  |\n",
    "| Parallel nodes      | Branch expansion  |\n",
    "| Persistent state    | Search memory     |\n",
    "| Checkpoints         | Backtracking      |\n",
    "| Human-in-the-loop   | Branch validation |\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Variants of Tree of Thought**\n",
    "\n",
    "| Variant           | Description                        |\n",
    "| ----------------- | ---------------------------------- |\n",
    "| Breadth-First ToT | Explore all branches at each depth |\n",
    "| Depth-First ToT   | Explore one branch deeply          |\n",
    "| Beam Search ToT   | Keep top-K branches                |\n",
    "| Monte Carlo ToT   | Randomized sampling                |\n",
    "| Heuristic ToT     | Domain-specific scoring            |\n",
    "| Hybrid ToT        | Combine strategies                 |\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Practical Applications**\n",
    "\n",
    "* Mathematical proof generation\n",
    "* Strategic planning\n",
    "* Code synthesis\n",
    "* Game playing\n",
    "* Scientific reasoning\n",
    "* Business decision support\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Mental Model**\n",
    "\n",
    "Tree of Thought transforms LLMs from **text generators** into **search-based problem solvers**:\n",
    "\n",
    "> **Reasoning = Search over possible thoughts**\n",
    "\n",
    "LangGraph provides the execution substrate that makes this search **explicit, controllable, safe, and scalable**.\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b54dd3c0-34b0-4acb-b10b-7dab329827c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL BEST IDEA:\n",
      " 1. **Conduct a Traffic Analysis**: Gather data on current traffic patterns, peak congestion times, and the most congested areas in the city. Utilize tools like traffic modeling software and surveys to identify the causes of congestion, such as road capacity, public transportation availability, and urban layout.\n"
     ]
    }
   ],
   "source": [
    "# ===================== Tree of Thought with LangGraph =====================\n",
    "\n",
    "from typing import TypedDict, List, Dict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# --------------------- State Definition ---------------------\n",
    "\n",
    "class State(TypedDict):\n",
    "    problem: str\n",
    "    thoughts: List[str]\n",
    "    scores: Dict[str, float]\n",
    "    best: str\n",
    "    depth: int\n",
    "\n",
    "# --------------------- Nodes ---------------------\n",
    "\n",
    "def generate(state: State):\n",
    "    prompt = f\"\"\"\n",
    "    Generate 3 possible next reasoning steps for solving:\n",
    "    {state['problem']}\n",
    "    \"\"\"\n",
    "    output = llm.invoke(prompt).content\n",
    "    thoughts = [t.strip() for t in output.split(\"\\n\") if t.strip()]\n",
    "    return {\"thoughts\": thoughts}\n",
    "\n",
    "def evaluate(state: State):\n",
    "    scores = {}\n",
    "    for t in state[\"thoughts\"]:\n",
    "        s = llm.invoke(f\"Score this step from 0-10: return only integer\\n{t}\").content\n",
    "        scores[t] = float(s)\n",
    "    best = max(scores, key=scores.get)\n",
    "    return {\"scores\": scores, \"best\": best, \"depth\": state[\"depth\"] + 1}\n",
    "\n",
    "def route(state: State):\n",
    "    if state[\"depth\"] >= 3:\n",
    "        return END\n",
    "    return \"generate\"\n",
    "\n",
    "# --------------------- Graph ---------------------\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"generate\", generate)\n",
    "builder.add_node(\"evaluate\", evaluate)\n",
    "\n",
    "builder.set_entry_point(\"generate\")\n",
    "builder.add_edge(\"generate\", \"evaluate\")\n",
    "builder.add_conditional_edges(\"evaluate\", route, {\"generate\": \"generate\", END: END})\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# --------------------- Run ---------------------\n",
    "\n",
    "result = graph.invoke({\n",
    "    \"problem\": \"Design a plan to reduce traffic congestion in a large city\",\n",
    "    \"thoughts\": [],\n",
    "    \"scores\": {},\n",
    "    \"best\": \"\",\n",
    "    \"depth\": 0\n",
    "})\n",
    "\n",
    "print(\"\\nFINAL BEST IDEA:\\n\", result[\"best\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eacc12a-fdcd-4368-bba6-119ba7c9394c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "py312env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
