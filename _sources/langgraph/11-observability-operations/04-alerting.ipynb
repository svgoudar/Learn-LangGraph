{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f1d8f2-a7fa-43dd-bfaf-d9e166156164",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Alerting\n",
    "\n",
    "**Alerting** in LangGraph refers to the **systematic detection, signaling, and handling of abnormal, risky, or significant events during graph execution**, enabling operators and systems to **respond in real time** to failures, performance degradation, policy violations, and business-critical conditions.\n",
    "\n",
    "Alerting transforms LangGraph from a workflow engine into a **production-grade autonomous system**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Why Alerting Is Required in LangGraph**\n",
    "\n",
    "LLM workflows are:\n",
    "\n",
    "* Long-running\n",
    "* Non-deterministic\n",
    "* Tool-dependent\n",
    "* Cost-sensitive\n",
    "* Business-critical\n",
    "\n",
    "Failures cannot remain silent.\n",
    "\n",
    "| Without Alerting          | With Alerting        |\n",
    "| ------------------------- | -------------------- |\n",
    "| Silent failures           | Immediate visibility |\n",
    "| Hidden cost explosions    | Budget protection    |\n",
    "| Undetected hallucinations | Safety enforcement   |\n",
    "| Manual debugging          | Automated response   |\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Alerting Architecture**\n",
    "\n",
    "```\n",
    "Graph Execution\n",
    "      |\n",
    "State + Events\n",
    "      |\n",
    "Alert Conditions\n",
    "      |\n",
    "Alert Engine\n",
    "      |\n",
    "Channels (Slack, Email, PagerDuty, Webhooks)\n",
    "```\n",
    "\n",
    "Alerting is **orthogonal to execution**: it observes execution without altering control flow unless configured to do so.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Alert Triggers in LangGraph**\n",
    "\n",
    "Alerts are generated from **runtime signals**:\n",
    "\n",
    "| Category    | Examples                                       |\n",
    "| ----------- | ---------------------------------------------- |\n",
    "| Execution   | Node failure, timeout, infinite loop           |\n",
    "| State       | Invalid state, missing fields, corruption      |\n",
    "| Performance | Latency spike, retry storm                     |\n",
    "| Cost        | Token overrun, model budget breach             |\n",
    "| Safety      | Policy violation, unsafe tool usage            |\n",
    "| Quality     | Low confidence output, hallucination detection |\n",
    "| Business    | SLA breach, workflow failure                   |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Alerting Implementation Pattern**\n",
    "\n",
    "### **A. Define Alert Conditions**\n",
    "\n",
    "```python\n",
    "def cost_alert(state):\n",
    "    if state[\"token_usage\"] > 50_000:\n",
    "        return True\n",
    "    return False\n",
    "```\n",
    "\n",
    "### **B. Attach Alert Node**\n",
    "\n",
    "```python\n",
    "def alert_node(state):\n",
    "    send_slack(f\"High cost detected: {state['token_usage']}\")\n",
    "    return {}\n",
    "```\n",
    "\n",
    "### **C. Integrate into Graph**\n",
    "\n",
    "```python\n",
    "builder.add_node(\"alert\", alert_node)\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"monitor\",\n",
    "    lambda s: \"alert\" if cost_alert(s) else \"next_step\",\n",
    "    {\"alert\": \"alert\", \"next_step\": \"next_step\"}\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Centralized Alert Manager (Production)**\n",
    "\n",
    "In production, alerting is implemented as a **cross-cutting service**:\n",
    "\n",
    "```\n",
    "Graph Runtime â†’ Event Bus â†’ Alert Manager â†’ Notification Systems\n",
    "```\n",
    "\n",
    "#### Responsibilities\n",
    "\n",
    "* Event aggregation\n",
    "* Rule evaluation\n",
    "* De-duplication\n",
    "* Throttling\n",
    "* Escalation\n",
    "* Audit logging\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Alert Severity Levels**\n",
    "\n",
    "| Level    | Meaning       |\n",
    "| -------- | ------------- |\n",
    "| INFO     | Observational |\n",
    "| WARNING  | Degradation   |\n",
    "| ERROR    | Failure       |\n",
    "| CRITICAL | System outage |\n",
    "| SECURITY | Policy breach |\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Automated Responses**\n",
    "\n",
    "Alerts can trigger **control actions**:\n",
    "\n",
    "| Action                 | Effect             |\n",
    "| ---------------------- | ------------------ |\n",
    "| Pause graph            | Prevent damage     |\n",
    "| Rollback state         | Recover            |\n",
    "| Switch model           | Degrade gracefully |\n",
    "| Request human approval | Safety             |\n",
    "| Kill workflow          | Emergency stop     |\n",
    "\n",
    "```python\n",
    "if alert.severity == \"CRITICAL\":\n",
    "    graph.interrupt(thread_id)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Observability Integration**\n",
    "\n",
    "| Tool       | Purpose           |\n",
    "| ---------- | ----------------- |\n",
    "| LangSmith  | Execution tracing |\n",
    "| Prometheus | Metrics           |\n",
    "| Grafana    | Dashboards        |\n",
    "| PagerDuty  | On-call           |\n",
    "| Slack      | Team alerts       |\n",
    "| ELK Stack  | Log analysis      |\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Example: Production Alert Scenario**\n",
    "\n",
    "**Case: Cost Explosion**\n",
    "\n",
    "1. LLM token usage exceeds threshold\n",
    "2. Alert engine triggers\n",
    "3. Slack + PagerDuty notified\n",
    "4. Graph paused\n",
    "5. Model downgraded\n",
    "6. Human review required\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Alerting vs Exception Handling**\n",
    "\n",
    "| Feature     | Exception Handling | Alerting         |\n",
    "| ----------- | ------------------ | ---------------- |\n",
    "| Scope       | Code-level         | System-level     |\n",
    "| Purpose     | Stop execution     | Notify & respond |\n",
    "| Audience    | Developer          | Operator / SRE   |\n",
    "| Persistence | Local              | Logged & audited |\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Design Principles**\n",
    "\n",
    "* Alerts must be **actionable**\n",
    "* Minimize noise\n",
    "* Tie alerts to **business impact**\n",
    "* Enforce **automatic safety responses**\n",
    "* Maintain **auditability**\n",
    "\n",
    "---\n",
    "\n",
    "### **12. Mental Model**\n",
    "\n",
    "> **Alerting = Nervous System of a LangGraph Application**\n",
    "\n",
    "It senses pain, triggers reflexes, and calls for help.\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0fc41d-39ec-45d9-8e8f-571dadfe6de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM used 10769 tokens | total = 10769\n",
      "LLM used 19857 tokens | total = 30626\n",
      "LLM used 17246 tokens | total = 47872\n",
      "LLM used 18840 tokens | total = 66712\n",
      "ðŸš¨ ALERT: Token budget exceeded!\n",
      "Pausing workflow and requesting human review.\n",
      "\n",
      "Final State: {'token_usage': 66712, 'status': 'paused'}\n"
     ]
    }
   ],
   "source": [
    "# --- One-Cell LangGraph Alerting Demo ---\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "import random\n",
    "\n",
    "# ---------- 1. Define State ----------\n",
    "\n",
    "class State(TypedDict):\n",
    "    token_usage: int\n",
    "    status: str\n",
    "\n",
    "# ---------- 2. Simulated Nodes ----------\n",
    "\n",
    "def llm_node(state):\n",
    "    # simulate token usage\n",
    "    new_tokens = random.randint(5_000, 20_000)\n",
    "    total = state[\"token_usage\"] + new_tokens\n",
    "    print(f\"LLM used {new_tokens} tokens | total = {total}\")\n",
    "    return {\"token_usage\": total, \"status\": \"running\"}\n",
    "\n",
    "def monitor_node(state):\n",
    "    return {}\n",
    "\n",
    "# ---------- 3. Alert Logic ----------\n",
    "\n",
    "MAX_TOKENS = 50_000\n",
    "\n",
    "def alert_condition(state):\n",
    "    return \"alert\" if state[\"token_usage\"] > MAX_TOKENS else \"continue\"\n",
    "\n",
    "def alert_node(state):\n",
    "    print(\"ðŸš¨ ALERT: Token budget exceeded!\")\n",
    "    print(\"Pausing workflow and requesting human review.\")\n",
    "    return {\"status\": \"paused\"}\n",
    "\n",
    "# ---------- 4. Build Graph ----------\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"llm\", llm_node)\n",
    "builder.add_node(\"monitor\", monitor_node)\n",
    "builder.add_node(\"alert\", alert_node)\n",
    "\n",
    "builder.set_entry_point(\"llm\")\n",
    "builder.add_edge(\"llm\", \"monitor\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"monitor\",\n",
    "    alert_condition,\n",
    "    {\"alert\": \"alert\", \"continue\": \"llm\"}\n",
    ")\n",
    "\n",
    "builder.add_edge(\"alert\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# ---------- 5. Run ----------\n",
    "\n",
    "result = graph.invoke({\"token_usage\": 0, \"status\": \"start\"}, \n",
    "                      config={\"recursion_limit\": 10})\n",
    "\n",
    "print(\"\\nFinal State:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "py312env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
