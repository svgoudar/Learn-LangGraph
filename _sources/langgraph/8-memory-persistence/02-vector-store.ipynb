{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cabd485b-1c47-4238-9c00-b91c8012ed8c",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## **Vector Store in LangGraph**\n",
    "\n",
    "A **vector store** is a specialized database that stores **dense numerical representations (embeddings)** of data and enables **semantic retrieval** through similarity search.\n",
    "In LangGraph, vector stores serve as the backbone for **long-term memory, knowledge grounding, tool augmentation, and agent reasoning**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Why Vector Stores Exist**\n",
    "\n",
    "Traditional databases retrieve data using **exact matches**.\n",
    "LLM systems require retrieval by **meaning**.\n",
    "\n",
    "| Requirement         | Traditional DB | Vector Store |\n",
    "| ------------------- | -------------- | ------------ |\n",
    "| Keyword match       | ✔              | ✖            |\n",
    "| Semantic match      | ✖              | ✔            |\n",
    "| Fuzzy retrieval     | ✖              | ✔            |\n",
    "| Reasoning memory    | ✖              | ✔            |\n",
    "| Knowledge grounding | ✖              | ✔            |\n",
    "\n",
    "Vector stores solve the **semantic retrieval problem**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Core Concept**\n",
    "\n",
    "```\n",
    "Raw Data ──Embedding Model──► Vector ──Stored in DB\n",
    "                                     │\n",
    "Query ──Embedding Model──► Query Vector ──Similarity Search──► Relevant Knowledge\n",
    "```\n",
    "\n",
    "Vectors capture **semantic meaning** in high-dimensional space.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Role of Vector Store in LangGraph**\n",
    "\n",
    "In LangGraph, vector stores integrate with the **stateful execution engine**:\n",
    "\n",
    "```\n",
    "Graph State ⇄ Vector Store ⇄ LLM Reasoning ⇄ Tool Execution\n",
    "```\n",
    "\n",
    "They provide:\n",
    "\n",
    "* **Long-term memory**\n",
    "* **Context augmentation**\n",
    "* **Agent knowledge grounding**\n",
    "* **Experience replay**\n",
    "* **Historical recall**\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Where Vector Stores Fit in a LangGraph Workflow**\n",
    "\n",
    "```\n",
    "User Query\n",
    "   ↓\n",
    "Embed Query\n",
    "   ↓\n",
    "Retrieve Relevant Documents  ←── Vector Store\n",
    "   ↓\n",
    "Inject into State\n",
    "   ↓\n",
    "LLM Node\n",
    "   ↓\n",
    "Next Decision\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Minimal Working Example**\n",
    "\n",
    "```python\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "docs = [Document(page_content=\"LangGraph manages stateful workflows.\")]\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "def retrieve(state):\n",
    "    query = state[\"query\"]\n",
    "    results = db.similarity_search(query, k=3)\n",
    "    return {\"context\": [r.page_content for r in results]}\n",
    "```\n",
    "\n",
    "Used inside a LangGraph node.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. State Integration**\n",
    "\n",
    "```python\n",
    "class State(TypedDict):\n",
    "    query: str\n",
    "    context: list[str]\n",
    "```\n",
    "\n",
    "Vector results become part of the shared state for downstream reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Vector Store Variants**\n",
    "\n",
    "| Type                               | Use Case              |\n",
    "| ---------------------------------- | --------------------- |\n",
    "| In-memory (FAISS)                  | Fast, local           |\n",
    "| Cloud (Pinecone, Weaviate, Milvus) | Scalable              |\n",
    "| Hybrid (Elastic + vectors)         | Structured + semantic |\n",
    "| Personal memory store              | Agent memory          |\n",
    "| Knowledge base                     | Enterprise documents  |\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Retrieval Strategies**\n",
    "\n",
    "| Strategy             | Description               |\n",
    "| -------------------- | ------------------------- |\n",
    "| k-NN                 | Top-k similar vectors     |\n",
    "| MMR                  | Diversity-aware retrieval |\n",
    "| Hybrid search        | Keyword + vector          |\n",
    "| Metadata filtering   | Context constraints       |\n",
    "| Time-aware retrieval | Recency bias              |\n",
    "| Role-based retrieval | Security control          |\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Advanced Patterns in LangGraph**\n",
    "\n",
    "| Pattern                  | Purpose                         |\n",
    "| ------------------------ | ------------------------------- |\n",
    "| Memory Agent             | Persistent personal memory      |\n",
    "| Knowledge Grounding      | Reduce hallucinations           |\n",
    "| Tool-Augmented Retrieval | Combine tools + memory          |\n",
    "| Experience Replay        | Learning from history           |\n",
    "| Self-Improving Memory    | Update vector store dynamically |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Production Architecture**\n",
    "\n",
    "```\n",
    "LangGraph Runtime\n",
    "      │\n",
    "State Store ──► Vector Store ──► Embedding Model\n",
    "      │                 │\n",
    "Checkpoint DB       Knowledge DB\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Why Vector Stores Are Critical for Agents**\n",
    "\n",
    "Without vector stores:\n",
    "\n",
    "* Agents forget\n",
    "* No grounding\n",
    "* High hallucination\n",
    "* No learning\n",
    "\n",
    "With vector stores:\n",
    "\n",
    "* Persistent memory\n",
    "* Context awareness\n",
    "* Knowledge grounding\n",
    "* Improved reasoning\n",
    "\n",
    "---\n",
    "\n",
    "### **12. Mental Model**\n",
    "\n",
    "> **Vector store = long-term semantic memory of the LangGraph system**\n",
    "\n",
    "It allows LangGraph to behave like a **learning, remembering, reasoning system**, not just a prompt pipeline.\n",
    "\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0cb6851-f449-4ce7-93f7-71bc88466f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How does LangGraph help agents?',\n",
       " 'context': ['LangGraph enables stateful agent workflows.',\n",
       "  'Cyclic graphs enable self-correction and planning.'],\n",
       " 'answer': 'Answer based on memory: LangGraph enables stateful agent workflows. Cyclic graphs enable self-correction and planning.'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_classic.vectorstores import FAISS\n",
    "from langchain_classic.schema import Document\n",
    "\n",
    "# -------------------- 1. Build Vector Store --------------------\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=\"LangGraph enables stateful agent workflows.\"),\n",
    "    Document(page_content=\"Vector stores provide long-term memory for LLMs.\"),\n",
    "    Document(page_content=\"Cyclic graphs enable self-correction and planning.\"),\n",
    "]\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# -------------------- 2. Define Graph State --------------------\n",
    "\n",
    "class State(TypedDict):\n",
    "    query: str\n",
    "    context: List[str]\n",
    "    answer: str\n",
    "\n",
    "# -------------------- 3. Graph Nodes --------------------\n",
    "\n",
    "def retrieve(state: State):\n",
    "    results = db.similarity_search(state[\"query\"], k=2)\n",
    "    return {\"context\": [r.page_content for r in results]}\n",
    "\n",
    "def reason(state: State):\n",
    "    joined = \" \".join(state[\"context\"])\n",
    "    return {\"answer\": f\"Answer based on memory: {joined}\"}\n",
    "\n",
    "# -------------------- 4. Build LangGraph --------------------\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"retrieve\", retrieve)\n",
    "builder.add_node(\"reason\", reason)\n",
    "\n",
    "builder.set_entry_point(\"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"reason\")\n",
    "builder.add_edge(\"reason\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# -------------------- 5. Run --------------------\n",
    "\n",
    "result = graph.invoke({\"query\": \"How does LangGraph help agents?\"})\n",
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "py312env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
