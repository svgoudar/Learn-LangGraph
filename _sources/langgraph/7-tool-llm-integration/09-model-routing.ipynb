{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc371ca2-cd91-498c-a12b-ba1e717de8fd",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Model Routing\n",
    "\n",
    "**Model Routing** in LangGraph is the mechanism by which the system dynamically selects **which LLM (or set of LLMs)** should handle a given step of execution based on **task requirements, state, cost, latency, accuracy, or policy constraints**.\n",
    "It enables **adaptive, cost-efficient, and production-grade multi-model systems**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Why Model Routing Exists**\n",
    "\n",
    "Modern LLM systems operate under competing constraints:\n",
    "\n",
    "| Constraint     | Reality                                          |\n",
    "| -------------- | ------------------------------------------------ |\n",
    "| Accuracy       | Large models perform better                      |\n",
    "| Cost           | Large models are expensive                       |\n",
    "| Latency        | Smaller models are faster                        |\n",
    "| Context length | Some models handle longer context                |\n",
    "| Capabilities   | Some models specialize (code, vision, reasoning) |\n",
    "\n",
    "A single static model is inefficient.\n",
    "**Routing allows each task step to use the most appropriate model.**\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Core Idea**\n",
    "\n",
    "```\n",
    "State → Router → Model Selection → Execution → State Update\n",
    "```\n",
    "\n",
    "The router decides the model **at runtime** based on the evolving state.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Where Routing Happens in LangGraph**\n",
    "\n",
    "Routing is implemented as a **router node** that returns:\n",
    "\n",
    "* Which model to use\n",
    "* Which node to execute next\n",
    "\n",
    "```python\n",
    "def model_router(state):\n",
    "    if state[\"task\"] == \"coding\":\n",
    "        return \"code_model\"\n",
    "    elif state[\"complexity\"] > 7:\n",
    "        return \"large_model\"\n",
    "    else:\n",
    "        return \"small_model\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Architecture Pattern**\n",
    "\n",
    "```\n",
    "            ┌──────────────┐\n",
    "State ───▶  │ Model Router │\n",
    "            └──────┬───────┘\n",
    "                   │\n",
    "     ┌─────────────┼─────────────┐\n",
    "     ↓             ↓             ↓\n",
    " Small LLM     Large LLM     Code LLM\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Minimal Working Example**\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    prompt: str\n",
    "    complexity: int\n",
    "    response: str\n",
    "\n",
    "def small_model(state):\n",
    "    return {\"response\": f\"SMALL: {state['prompt']}\"}\n",
    "\n",
    "def large_model(state):\n",
    "    return {\"response\": f\"LARGE: {state['prompt']}\"}\n",
    "\n",
    "def router(state):\n",
    "    return \"large\" if state[\"complexity\"] > 5 else \"small\"\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"small\", small_model)\n",
    "builder.add_node(\"large\", large_model)\n",
    "\n",
    "builder.add_conditional_edges(\"router\", router, {\n",
    "    \"small\": \"small\",\n",
    "    \"large\": \"large\"\n",
    "})\n",
    "\n",
    "builder.set_entry_point(\"router\")\n",
    "builder.add_edge(\"small\", END)\n",
    "builder.add_edge(\"large\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Advanced Routing Criteria**\n",
    "\n",
    "| Factor     | Routing Logic                   |\n",
    "| ---------- | ------------------------------- |\n",
    "| Input size | Large context → large model     |\n",
    "| Task type  | Code → code model               |\n",
    "| User tier  | Premium → stronger model        |\n",
    "| Budget     | Low → smaller model             |\n",
    "| Latency    | Realtime → fast model           |\n",
    "| Risk level | High risk → best model          |\n",
    "| Language   | Non-English → specialized model |\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Production-Grade Model Routing**\n",
    "\n",
    "| Feature            | Implementation               |\n",
    "| ------------------ | ---------------------------- |\n",
    "| Multi-model pool   | OpenAI, Claude, local models |\n",
    "| Cost tracking      | Token usage + budget guard   |\n",
    "| Fallback           | Automatic model failover     |\n",
    "| Canary routing     | Test new models safely       |\n",
    "| A/B routing        | Quality evaluation           |\n",
    "| Policy enforcement | Compliance rules             |\n",
    "| Observability      | Per-model metrics            |\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Model Routing with Loops & Agents**\n",
    "\n",
    "In agent systems, routing happens **inside cycles**:\n",
    "\n",
    "```\n",
    "Plan → Choose Model → Execute → Evaluate → Re-route → Repeat\n",
    "```\n",
    "\n",
    "This enables **adaptive intelligence**.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Common Routing Variants**\n",
    "\n",
    "| Variant              | Description              |\n",
    "| -------------------- | ------------------------ |\n",
    "| Static routing       | Fixed model per node     |\n",
    "| Dynamic routing      | State-based decisions    |\n",
    "| Hierarchical routing | Supervisor selects model |\n",
    "| Ensemble routing     | Multiple models vote     |\n",
    "| Fallback routing     | Failover on error        |\n",
    "| Budget-aware routing | Stops overspending       |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Mental Model**\n",
    "\n",
    "Model routing turns LangGraph from a static workflow into a **self-optimizing AI system**:\n",
    "\n",
    "> **Right model, right task, right time.**\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad4157b-99da-4ace-85c1-68501b2db84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Explain AI', 'complexity': 3, 'response': '[SMALL MODEL] Explain AI'}\n",
      "{'prompt': 'Prove convergence of SGD', 'complexity': 9, 'response': '[LARGE MODEL] Prove convergence of SGD'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "\n",
    "# -------------------- State Definition --------------------\n",
    "\n",
    "class State(TypedDict):\n",
    "    prompt: str\n",
    "    complexity: int\n",
    "    response: str\n",
    "\n",
    "# -------------------- Models (simulated) --------------------\n",
    "\n",
    "def small_model(state: State):\n",
    "    return {\"response\": f\"[SMALL MODEL] {state['prompt']}\"}\n",
    "\n",
    "def large_model(state: State):\n",
    "    return {\"response\": f\"[LARGE MODEL] {state['prompt']}\"}\n",
    "\n",
    "# -------------------- Router --------------------\n",
    "\n",
    "def model_router(state: State):\n",
    "    if state[\"complexity\"] > 5:\n",
    "        return \"large\"\n",
    "    else:\n",
    "        return \"small\"\n",
    "\n",
    "# -------------------- Build Graph --------------------\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"router\", lambda state: state)\n",
    "builder.add_node(\"small\", small_model)\n",
    "builder.add_node(\"large\", large_model)\n",
    "\n",
    "builder.set_entry_point(\"router\")\n",
    "\n",
    "builder.add_conditional_edges(\"router\", model_router, {\n",
    "    \"small\": \"small\",\n",
    "    \"large\": \"large\"\n",
    "})\n",
    "\n",
    "builder.add_edge(\"small\", END)\n",
    "builder.add_edge(\"large\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# -------------------- Run Examples --------------------\n",
    "\n",
    "print(graph.invoke({\"prompt\": \"Explain AI\", \"complexity\": 3}))\n",
    "print(graph.invoke({\"prompt\": \"Prove convergence of SGD\", \"complexity\": 9}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab452c-9290-49c1-863a-ccb586751b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
