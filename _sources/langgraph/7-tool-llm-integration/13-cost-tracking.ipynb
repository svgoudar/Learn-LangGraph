{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf3413dd-5af7-4aa3-8829-206abd3f96c2",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## **Cost Tracking in LangGraph**\n",
    "\n",
    "**Cost Tracking** in LangGraph is the systematic measurement, attribution, and control of **monetary cost, token usage, and resource consumption** across complex LLM workflows.\n",
    "It is a **first-class production concern** because LangGraph systems often involve **multiple models, agents, tools, loops, retries, and long-running executions**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Why Cost Tracking Is Necessary**\n",
    "\n",
    "In simple chains, cost ≈ one LLM call.\n",
    "In LangGraph, cost accumulates across:\n",
    "\n",
    "| Source            | Examples                    |\n",
    "| ----------------- | --------------------------- |\n",
    "| Multiple nodes    | Planner, executor, verifier |\n",
    "| Cyclic loops      | Reflection, retries         |\n",
    "| Parallel agents   | Multi-agent debate          |\n",
    "| Tool calls        | Search APIs, databases      |\n",
    "| Retries & backoff | Error recovery              |\n",
    "| Human-in-the-loop | Long sessions               |\n",
    "\n",
    "Without cost tracking, **real spend becomes unpredictable and dangerous in production**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Cost Model in LangGraph**\n",
    "\n",
    "Each graph execution produces **structured cost signals**:\n",
    "\n",
    "| Layer   | What is Measured                 |\n",
    "| ------- | -------------------------------- |\n",
    "| LLM     | prompt tokens, completion tokens |\n",
    "| Model   | per-token pricing                |\n",
    "| Tool    | API fees                         |\n",
    "| Runtime | execution time, memory           |\n",
    "| Agents  | per-agent cost                   |\n",
    "| Session | cumulative cost                  |\n",
    "| Tenant  | per-user / per-organization cost |\n",
    "\n",
    "Total cost =\n",
    "**Σ (LLM tokens × price) + tool usage + infrastructure overhead**\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Where Cost Is Collected**\n",
    "\n",
    "LangGraph integrates with **LangChain callbacks**.\n",
    "\n",
    "```\n",
    "Graph Execution\n",
    "   └─ Node\n",
    "       └─ LLM / Tool\n",
    "           └─ Callback → Cost Recorder\n",
    "```\n",
    "\n",
    "This allows **fine-grained cost attribution per node, per agent, per run**.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Minimal Cost Tracking Example**\n",
    "\n",
    "```python\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = graph.invoke(input_state)\n",
    "\n",
    "print(\"Total tokens:\", cb.total_tokens)\n",
    "print(\"Prompt tokens:\", cb.prompt_tokens)\n",
    "print(\"Completion tokens:\", cb.completion_tokens)\n",
    "print(\"Total cost ($):\", cb.total_cost)\n",
    "```\n",
    "\n",
    "This captures **full-graph cost**, including loops and subgraphs.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Node-Level Cost Attribution**\n",
    "\n",
    "```python\n",
    "def llm_node(state):\n",
    "    with get_openai_callback() as cb:\n",
    "        response = llm.invoke(state[\"input\"])\n",
    "    return {\n",
    "        \"output\": response,\n",
    "        \"node_cost\": cb.total_cost\n",
    "    }\n",
    "```\n",
    "\n",
    "You can accumulate this inside state:\n",
    "\n",
    "```python\n",
    "state[\"total_cost\"] += state[\"node_cost\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Agent-Level Cost Tracking**\n",
    "\n",
    "Each agent maintains its own cost ledger:\n",
    "\n",
    "| Agent     | Cost       |\n",
    "| --------- | ---------- |\n",
    "| Planner   | $0.021     |\n",
    "| Executor  | $0.114     |\n",
    "| Verifier  | $0.033     |\n",
    "| **Total** | **$0.168** |\n",
    "\n",
    "This enables:\n",
    "\n",
    "* Budget enforcement per agent\n",
    "* Optimization of expensive agents\n",
    "* Dynamic model routing\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Budget Enforcement & Circuit Breakers**\n",
    "\n",
    "```python\n",
    "def cost_guard(state):\n",
    "    if state[\"total_cost\"] > 1.00:\n",
    "        return END\n",
    "    return \"continue\"\n",
    "```\n",
    "\n",
    "Use as conditional edge:\n",
    "\n",
    "```python\n",
    "builder.add_conditional_edges(\"router\", cost_guard, {\n",
    "    \"continue\": \"next_node\",\n",
    "    END: END\n",
    "})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Cost-Aware Model Routing**\n",
    "\n",
    "```python\n",
    "def choose_model(state):\n",
    "    if state[\"total_cost\"] < 0.10:\n",
    "        return cheap_model\n",
    "    return premium_model\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Cost Persistence & Analytics**\n",
    "\n",
    "Store cost per:\n",
    "\n",
    "* Graph run\n",
    "* User session\n",
    "* Tenant\n",
    "* Time window\n",
    "\n",
    "Use this for:\n",
    "\n",
    "| Purpose      | Benefit                  |\n",
    "| ------------ | ------------------------ |\n",
    "| Billing      | Chargeback               |\n",
    "| Monitoring   | Cost anomaly detection   |\n",
    "| Optimization | Identify expensive paths |\n",
    "| Governance   | Enforce policies         |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Production Best Practices**\n",
    "\n",
    "| Principle           | Implementation         |\n",
    "| ------------------- | ---------------------- |\n",
    "| Always track        | Every graph run        |\n",
    "| Cap budgets         | Hard limits            |\n",
    "| Log costs           | Immutable logs         |\n",
    "| Alert               | On cost spikes         |\n",
    "| Optimize loops      | Prevent runaway cycles |\n",
    "| Prefer cheap models | For early stages       |\n",
    "| Batch calls         | Reduce overhead        |\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Mental Model**\n",
    "\n",
    "Think of LangGraph cost tracking as **distributed accounting**:\n",
    "\n",
    "> Every node spends.\n",
    "> Every agent accumulates.\n",
    "> The graph enforces discipline.\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d9540f7-01e6-42b1-8ef5-e2a055ce17db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output: LangGraph is a tool that visualizes the relationships between languages based on their linguistic similarities.\n",
      "Steps: 5\n",
      "Total Cost ($): 0.0001785\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_classic.callbacks import get_openai_callback\n",
    "\n",
    "# -------------------- State --------------------\n",
    "\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    total_cost: float\n",
    "    steps: int\n",
    "\n",
    "# -------------------- LLM --------------------\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# -------------------- Nodes --------------------\n",
    "\n",
    "def llm_node(state: State):\n",
    "    with get_openai_callback() as cb:\n",
    "        response = llm.invoke(state[\"input\"])\n",
    "    return {\n",
    "        \"output\": response.content,\n",
    "        \"total_cost\": state[\"total_cost\"] + cb.total_cost,\n",
    "        \"steps\": state[\"steps\"] + 1\n",
    "    }\n",
    "\n",
    "def cost_guard(state: State):\n",
    "    if state[\"total_cost\"] >= 0.01:     # hard budget\n",
    "        return END\n",
    "    if state[\"steps\"] >= 5:             # hard step limit\n",
    "        return END\n",
    "    return \"llm\"\n",
    "\n",
    "# -------------------- Graph --------------------\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"llm\", llm_node)\n",
    "builder.set_entry_point(\"llm\")\n",
    "\n",
    "builder.add_conditional_edges(\"llm\", cost_guard, {\n",
    "    \"llm\": \"llm\",\n",
    "    END: END\n",
    "})\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# -------------------- Run --------------------\n",
    "\n",
    "result = graph.invoke(\n",
    "    {\n",
    "        \"input\": \"Explain LangGraph in one sentence.\",\n",
    "        \"output\": \"\",\n",
    "        \"total_cost\": 0.0,\n",
    "        \"steps\": 0\n",
    "    },\n",
    "    config={\"recursion_limit\": 20}\n",
    ")\n",
    "\n",
    "print(\"Final Output:\", result[\"output\"])\n",
    "print(\"Steps:\", result[\"steps\"])\n",
    "print(\"Total Cost ($):\", result[\"total_cost\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
