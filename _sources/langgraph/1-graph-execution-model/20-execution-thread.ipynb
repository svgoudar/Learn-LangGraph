{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Execution Thread \n",
    "\n",
    "An **Execution Thread** in LangGraph is a **persistent, stateful control channel** that manages the lifecycle of a single graph run.\n",
    "It represents **one continuous workflow instance** — from entry node to termination — and preserves identity, memory, and checkpoints across time.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Conceptual Definition**\n",
    "\n",
    "An execution thread is:\n",
    "\n",
    "> A **unique, long-lived execution context** that carries state, memory, checkpoints, and control flow for one invocation of a LangGraph application.\n",
    "\n",
    "It enables:\n",
    "\n",
    "* Stateful workflows\n",
    "* Multi-turn conversations\n",
    "* Human-in-the-loop execution\n",
    "* Pausing, resuming, and recovery\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Why Execution Threads Exist**\n",
    "\n",
    "Without threads, LLM workflows are **stateless function calls**.\n",
    "\n",
    "With threads, workflows become **persistent programs**.\n",
    "\n",
    "| Capability     | Stateless Call    | Execution Thread |\n",
    "| -------------- | ----------------- | ---------------- |\n",
    "| Memory         | ❌ Lost after call | ✅ Persistent     |\n",
    "| Pause / Resume | ❌                 | ✅                |\n",
    "| Multi-turn     | ❌                 | ✅                |\n",
    "| Checkpointing  | ❌                 | ✅                |\n",
    "| Recovery       | ❌                 | ✅                |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Execution Thread Components**\n",
    "\n",
    "Each execution thread encapsulates:\n",
    "\n",
    "| Component          | Role                       |\n",
    "| ------------------ | -------------------------- |\n",
    "| Thread ID          | Unique identity of the run |\n",
    "| State              | Shared mutable data        |\n",
    "| Checkpoint History | Saved snapshots            |\n",
    "| Execution Cursor   | Current node pointer       |\n",
    "| Execution Log      | Full trace                 |\n",
    "| Memory             | Short & long-term memory   |\n",
    "| Pending Tasks      | In-flight operations       |\n",
    "| Timeouts           | Safety controls            |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Execution Thread Lifecycle**\n",
    "\n",
    "```\n",
    "Create → Initialize → Execute → Checkpoint → Pause/Resume → Terminate → Archive\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Creating an Execution Thread**\n",
    "\n",
    "Threads are created implicitly via invocation:\n",
    "\n",
    "```python\n",
    "result = graph.invoke(input, config={\"thread_id\": \"user-123\"})\n",
    "```\n",
    "\n",
    "If the thread exists → resumes\n",
    "If not → creates new thread\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Threaded Multi-Turn Example**\n",
    "\n",
    "```python\n",
    "graph.invoke({\"message\": \"Plan my trip\"}, config={\"thread_id\": \"alice\"})\n",
    "graph.invoke({\"message\": \"Book hotel\"}, config={\"thread_id\": \"alice\"})\n",
    "```\n",
    "\n",
    "Both calls operate on the **same execution thread** and **same state**.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Checkpointing & Recovery**\n",
    "\n",
    "Every node execution creates a checkpoint:\n",
    "\n",
    "```\n",
    "[Node A] → Checkpoint 1\n",
    "[Node B] → Checkpoint 2\n",
    "[Node C] → Checkpoint 3\n",
    "```\n",
    "\n",
    "If failure occurs:\n",
    "\n",
    "```python\n",
    "graph.invoke(new_input, config={\"thread_id\": \"alice\"})\n",
    "```\n",
    "\n",
    "Execution resumes from the last safe checkpoint.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Thread Safety & Concurrency**\n",
    "\n",
    "| Feature          | Behavior                         |\n",
    "| ---------------- | -------------------------------- |\n",
    "| Thread Isolation | Threads do not share state       |\n",
    "| Concurrency      | Multiple threads run in parallel |\n",
    "| Consistency      | One active cursor per thread     |\n",
    "| Locking          | Prevents conflicting updates     |\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Human-in-the-Loop via Threads**\n",
    "\n",
    "```python\n",
    "graph.invoke(input, config={\"thread_id\": \"case-42\", \"interrupt_after\": [\"review\"]})\n",
    "```\n",
    "\n",
    "Execution pauses at `review`.\n",
    "Human modifies state → thread resumes.\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Production Use Cases**\n",
    "\n",
    "| Use Case   | Role of Thread           |\n",
    "| ---------- | ------------------------ |\n",
    "| Chatbots   | Each user = one thread   |\n",
    "| Agents     | One task = one thread    |\n",
    "| Workflows  | One job = one thread     |\n",
    "| Auditing   | One trace per thread     |\n",
    "| Compliance | Immutable thread history |\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Mental Model**\n",
    "\n",
    "An execution thread is to LangGraph what:\n",
    "\n",
    "* a **process** is to an OS\n",
    "* a **transaction** is to a database\n",
    "* a **session** is to a web app\n",
    "\n",
    "It transforms LLM workflows from **functions** into **programs**.\n",
    "\n",
    "---\n",
    "\n",
    "**12. Summary**\n",
    "\n",
    "> **Execution threads give LangGraph memory, continuity, safety, and control.**\n",
    "> They are the backbone of **reliable, long-running, production-grade LLM systems**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: list\n",
    "\n",
    "def chatbot(state: State):\n",
    "    new_msg = f\"Bot: I received -> {state['messages'][-1]}\"\n",
    "    return {\"messages\": state[\"messages\"] + [new_msg]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"chat\", chatbot)\n",
    "builder.set_entry_point(\"chat\")\n",
    "builder.add_edge(\"chat\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': ['Hello', 'Bot: I received -> Hello']}\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"user-1\"}}\n",
    "\n",
    "out1 = graph.invoke({\"messages\": [\"Hello\"]}, config)\n",
    "print(out1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': ['How are you?', 'Bot: I received -> How are you?']}\n"
     ]
    }
   ],
   "source": [
    "out2 = graph.invoke({\"messages\": [\"How are you?\"]}, config)\n",
    "print(out2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
