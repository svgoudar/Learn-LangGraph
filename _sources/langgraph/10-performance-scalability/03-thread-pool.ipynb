{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ab91c5",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Thread Pool\n",
    "\n",
    "A **thread pool** in LangGraph is a concurrency mechanism that allows **multiple nodes or graph invocations to execute simultaneously** by distributing work across a fixed set of worker threads.\n",
    "It is a critical building block for achieving **high throughput, low latency, and scalable agent systems**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Why Thread Pools Exist in LangGraph**\n",
    "\n",
    "LLM workflows are naturally parallel:\n",
    "\n",
    "* Multiple agents reason independently\n",
    "* Tool calls wait on I/O\n",
    "* Subgraphs execute concurrently\n",
    "* Multiple user sessions run in parallel\n",
    "\n",
    "Without controlled concurrency, systems either become **slow** or **unstable**.\n",
    "LangGraph uses thread pools to provide **bounded, efficient parallel execution**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Conceptual Model**\n",
    "\n",
    "```\n",
    "Incoming Graph Tasks\n",
    "        |\n",
    "   Task Scheduler\n",
    "        |\n",
    "   Thread Pool Executor\n",
    "    |     |     |\n",
    " Worker  Worker  Worker\n",
    " Thread  Thread  Thread\n",
    "    |     |     |\n",
    " Node   Node   Node\n",
    "```\n",
    "\n",
    "The thread pool:\n",
    "\n",
    "* Limits resource usage\n",
    "* Maximizes CPU utilization\n",
    "* Prevents system overload\n",
    "\n",
    "---\n",
    "\n",
    "### **3. How LangGraph Uses Thread Pools**\n",
    "\n",
    "LangGraph is built on **LangChain’s Runnable execution engine**, which uses Python’s `ThreadPoolExecutor` for parallel execution of nodes and subgraphs.\n",
    "\n",
    "It is used for:\n",
    "\n",
    "* Parallel node execution (`fan-out`)\n",
    "* Concurrent tool calls\n",
    "* Parallel agent execution\n",
    "* Serving multiple graph invocations\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Execution Flow with Thread Pool**\n",
    "\n",
    "1. Graph compiled into execution plan\n",
    "2. Scheduler identifies independent tasks\n",
    "3. Tasks submitted to thread pool\n",
    "4. Workers execute nodes concurrently\n",
    "5. Results merged into shared state\n",
    "6. Execution continues\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Demonstration: Parallel Nodes**\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "import time\n",
    "\n",
    "class State(TypedDict):\n",
    "    a: int\n",
    "    b: int\n",
    "\n",
    "def task1(state):\n",
    "    time.sleep(2)\n",
    "    return {\"a\": 1}\n",
    "\n",
    "def task2(state):\n",
    "    time.sleep(2)\n",
    "    return {\"b\": 2}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"t1\", task1)\n",
    "builder.add_node(\"t2\", task2)\n",
    "\n",
    "builder.set_entry_point(\"t1\")\n",
    "builder.add_edge(\"t1\", \"t2\")\n",
    "builder.add_edge(\"t2\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "graph.invoke({})\n",
    "```\n",
    "\n",
    "With proper parallel configuration, `task1` and `task2` can be executed concurrently in fan-out patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Fan-Out / Fan-In with Thread Pool**\n",
    "\n",
    "```\n",
    "          Start\n",
    "            |\n",
    "        ┌───┴───┐\n",
    "      Node A   Node B   ← parallel threads\n",
    "        └───┬───┘\n",
    "            |\n",
    "          Join\n",
    "```\n",
    "\n",
    "This structure relies on thread pools for efficient execution.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Production Configuration Concepts**\n",
    "\n",
    "| Parameter    | Purpose                    |\n",
    "| ------------ | -------------------------- |\n",
    "| max_workers  | Upper bound on concurrency |\n",
    "| Queue size   | Prevent overload           |\n",
    "| Task timeout | Avoid hung threads         |\n",
    "| Retry policy | Recover from failures      |\n",
    "| Backpressure | Slow input when saturated  |\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "import concurrent.futures\n",
    "\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=8)\n",
    "```\n",
    "\n",
    "LangGraph internally uses similar configuration via runtime settings.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Thread Pool vs Async IO**\n",
    "\n",
    "| Thread Pool             | Async IO             |\n",
    "| ----------------------- | -------------------- |\n",
    "| Good for blocking tasks | Best for network I/O |\n",
    "| CPU-bound operations    | High scalability     |\n",
    "| Simpler mental model    | More complex         |\n",
    "\n",
    "LangGraph supports **both**, but thread pools are the default for safe concurrency.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Performance & Safety Guidelines**\n",
    "\n",
    "* Never allow unbounded thread creation\n",
    "* Size pool to CPU cores + I/O needs\n",
    "* Isolate heavy agents in their own pools\n",
    "* Use timeouts and retries\n",
    "* Monitor thread saturation\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Why This Matters for Agents**\n",
    "\n",
    "Thread pools make it possible for LangGraph to run:\n",
    "\n",
    "* Multi-agent systems\n",
    "* Parallel tool execution\n",
    "* High-throughput APIs\n",
    "* Long-running autonomous workflows\n",
    "\n",
    "**without deadlocks, resource exhaustion, or latency collapse**.\n",
    "\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9dea5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task A started\n",
      "Task B started\n",
      "Task A finished\n",
      "Task B finished\n",
      "Join started\n",
      "\n",
      "Final State: {'x': 1, 'y': 2, 'z': 3}\n",
      "Total Time: 2.04 seconds\n"
     ]
    }
   ],
   "source": [
    "# One-cell demonstration: Thread Pool style parallelism in LangGraph\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "import time\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Define Shared State\n",
    "# ----------------------------\n",
    "\n",
    "class State(TypedDict):\n",
    "    x: int\n",
    "    y: int\n",
    "    z: int\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Define Parallel Tasks\n",
    "# ----------------------------\n",
    "\n",
    "def start(state):\n",
    "    return state\n",
    "\n",
    "def task_a(state):\n",
    "    print(\"Task A started\")\n",
    "    time.sleep(2)\n",
    "    print(\"Task A finished\")\n",
    "    return {\"x\": 1}\n",
    "\n",
    "def task_b(state):\n",
    "    print(\"Task B started\")\n",
    "    time.sleep(2)\n",
    "    print(\"Task B finished\")\n",
    "    return {\"y\": 2}\n",
    "\n",
    "def join_task(state):\n",
    "    print(\"Join started\")\n",
    "    return {\"z\": state[\"x\"] + state[\"y\"]}\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Build Graph\n",
    "# ----------------------------\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"start\", start)\n",
    "builder.add_node(\"A\", task_a)\n",
    "builder.add_node(\"B\", task_b)\n",
    "builder.add_node(\"JOIN\", join_task)\n",
    "\n",
    "builder.set_entry_point(\"start\")\n",
    "\n",
    "# Fan-out: start triggers both A and B in parallel\n",
    "builder.add_edge(\"start\", \"A\")\n",
    "builder.add_edge(\"start\", \"B\")\n",
    "\n",
    "# Fan-in: both A and B converge to JOIN\n",
    "builder.add_edge(\"A\", \"JOIN\")\n",
    "builder.add_edge(\"B\", \"JOIN\")\n",
    "\n",
    "builder.add_edge(\"JOIN\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Run\n",
    "# ----------------------------\n",
    "\n",
    "start = time.time()\n",
    "result = graph.invoke({})\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nFinal State:\", result)\n",
    "print(\"Total Time:\", round(end - start, 2), \"seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
