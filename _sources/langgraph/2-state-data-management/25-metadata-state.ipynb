{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95fb5fa7",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## **Metadata State in LangGraph**\n",
    "\n",
    "In LangGraph, the **Metadata State** is the structured, auxiliary information attached to a workflow’s execution state that describes **how**, **when**, **why**, and **under what conditions** each step of the graph executes.\n",
    "It does **not** represent the task’s main data (e.g., messages, plans, results) but instead governs **execution control, observability, safety, reproducibility, and production behavior**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Conceptual Definition**\n",
    "\n",
    "Let the full state be:\n",
    "\n",
    "[\n",
    "\\text{State} = \\text{Task State} ; \\cup ; \\text{Metadata State}\n",
    "]\n",
    "\n",
    "| Component          | Role                                          |\n",
    "| ------------------ | --------------------------------------------- |\n",
    "| Task State         | Domain data (messages, plan, results, memory) |\n",
    "| **Metadata State** | Execution context and governance data         |\n",
    "\n",
    "Metadata makes LangGraph behave like a **production workflow engine**, not just an LLM pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. What Belongs in Metadata State**\n",
    "\n",
    "| Category                | Examples                                    |\n",
    "| ----------------------- | ------------------------------------------- |\n",
    "| **Execution Control**   | `step_id`, `node_id`, `run_id`, `thread_id` |\n",
    "| **Timing & Cost**       | timestamps, token usage, latency, cost      |\n",
    "| **Routing Signals**     | confidence, score, decision flags           |\n",
    "| **Safety & Governance** | permissions, approval flags, risk level     |\n",
    "| **Observability**       | logs, trace IDs, metrics                    |\n",
    "| **Failure Handling**    | retries, error types, backoff count         |\n",
    "| **Versioning**          | graph version, model version                |\n",
    "| **Human-in-the-Loop**   | reviewer ID, comments, approvals            |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Designing Metadata State**\n",
    "\n",
    "```python\n",
    "class State(TypedDict):\n",
    "    messages: list\n",
    "    result: str\n",
    "    \n",
    "    # --- Metadata ---\n",
    "    step: int\n",
    "    run_id: str\n",
    "    trace_id: str\n",
    "    cost: float\n",
    "    latency_ms: float\n",
    "    approved: bool\n",
    "    retries: int\n",
    "    risk_level: str\n",
    "```\n",
    "\n",
    "This makes every node **self-aware of execution conditions**.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. How Metadata Flows Through the Graph**\n",
    "\n",
    "Nodes update metadata exactly like normal state:\n",
    "\n",
    "```python\n",
    "def reasoning_node(state):\n",
    "    start = time.time()\n",
    "\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "\n",
    "    latency = (time.time() - start) * 1000\n",
    "\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [response],\n",
    "        \"latency_ms\": latency,\n",
    "        \"step\": state[\"step\"] + 1\n",
    "    }\n",
    "```\n",
    "\n",
    "LangGraph automatically merges metadata using **reducers**.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Metadata-Driven Routing**\n",
    "\n",
    "Metadata often determines **control flow**.\n",
    "\n",
    "```python\n",
    "def router(state):\n",
    "    if state[\"risk_level\"] == \"high\" and not state[\"approved\"]:\n",
    "        return \"human_review\"\n",
    "    if state[\"retries\"] > 3:\n",
    "        return END\n",
    "    return \"execute\"\n",
    "```\n",
    "\n",
    "This enables:\n",
    "\n",
    "* Approval gates\n",
    "* Circuit breakers\n",
    "* Budget enforcement\n",
    "* Safety boundaries\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Metadata & Production Guarantees**\n",
    "\n",
    "| Problem            | Solved by Metadata         |\n",
    "| ------------------ | -------------------------- |\n",
    "| Infinite loops     | `step`, `max_steps`        |\n",
    "| Cost overruns      | `cost`, `token_usage`      |\n",
    "| Silent failures    | `error_type`, `retries`    |\n",
    "| Audit requirements | `trace_id`, timestamps     |\n",
    "| Compliance         | `approvals`, reviewer info |\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Metadata & Checkpointing**\n",
    "\n",
    "Every checkpoint stores:\n",
    "\n",
    "```\n",
    "Task State + Metadata State\n",
    "```\n",
    "\n",
    "Allowing:\n",
    "\n",
    "* Full execution replay\n",
    "* Partial rollback\n",
    "* Compliance auditing\n",
    "* Failure recovery\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Example: Safety-Controlled Loop**\n",
    "\n",
    "```python\n",
    "def should_continue(state):\n",
    "    if state[\"step\"] >= 10: \n",
    "        return END\n",
    "    if state[\"cost\"] > 2.00:\n",
    "        return END\n",
    "    return \"reason\"\n",
    "```\n",
    "\n",
    "This transforms LangGraph into a **governed autonomous system**.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Mental Model**\n",
    "\n",
    "Without metadata, a LangGraph system is:\n",
    "\n",
    "> A smart script\n",
    "\n",
    "With metadata, it becomes:\n",
    "\n",
    "> A **self-regulating distributed control system**\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Why Metadata State Is Fundamental**\n",
    "\n",
    "Metadata State is the **operating system layer** of LangGraph.\n",
    "It enables:\n",
    "\n",
    "* Reliability\n",
    "* Safety\n",
    "* Governance\n",
    "* Observability\n",
    "* Scalability\n",
    "* Enterprise readiness\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2fa42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "import time, uuid\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Task State\n",
    "    messages: List[str]\n",
    "    result: str\n",
    "\n",
    "    # Metadata State\n",
    "    step: int\n",
    "    run_id: str\n",
    "    cost: float\n",
    "    latency_ms: float\n",
    "    approved: bool\n",
    "    risk_level: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8d724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reason(state: State):\n",
    "    start = time.time()\n",
    "\n",
    "    msg = f\"Reasoning step {state['step']}\"\n",
    "    latency = (time.time() - start) * 1000\n",
    "\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [msg],\n",
    "        \"latency_ms\": latency,\n",
    "        \"cost\": state[\"cost\"] + 0.05,\n",
    "        \"step\": state[\"step\"] + 1\n",
    "    }\n",
    "\n",
    "def assess_risk(state: State):\n",
    "    risk = \"high\" if state[\"step\"] >= 3 else \"low\"\n",
    "    return {\"risk_level\": risk}\n",
    "\n",
    "def human_review(state: State):\n",
    "    print(\"\\nHuman approval required:\")\n",
    "    print(state[\"messages\"][-1])\n",
    "    approval = input(\"Approve? (y/n): \")\n",
    "    return {\"approved\": approval == \"y\"}\n",
    "\n",
    "\n",
    "def router(state: State):\n",
    "    if state[\"risk_level\"] == \"high\" and not state[\"approved\"]:\n",
    "        return \"human_review\"\n",
    "    if state[\"cost\"] > 0.25:\n",
    "        return END\n",
    "    if state[\"step\"] >= 5:\n",
    "        return END\n",
    "    return \"reason\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf991fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"reason\", reason)\n",
    "builder.add_node(\"assess_risk\", assess_risk)\n",
    "builder.add_node(\"human_review\", human_review)\n",
    "\n",
    "builder.set_entry_point(\"reason\")\n",
    "builder.add_edge(\"reason\", \"assess_risk\")\n",
    "\n",
    "builder.add_conditional_edges(\"assess_risk\", router, {\n",
    "    \"human_review\": \"human_review\",\n",
    "    \"reason\": \"reason\",\n",
    "    END: END\n",
    "})\n",
    "\n",
    "builder.add_edge(\"human_review\", \"reason\")\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b3e572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human approval required:\n",
      "Reasoning step 2\n",
      "\n",
      "Final State:\n",
      "{'messages': ['Reasoning step 0', 'Reasoning step 1', 'Reasoning step 2', 'Reasoning step 3', 'Reasoning step 4'], 'result': '', 'step': 5, 'run_id': 'e426ed8c-7985-4eba-aac2-d75c52a2bfb0', 'cost': 0.25, 'latency_ms': 0.0, 'approved': True, 'risk_level': 'high'}\n"
     ]
    }
   ],
   "source": [
    "initial_state: State = {\n",
    "    \"messages\": [],\n",
    "    \"result\": \"\",\n",
    "    \"step\": 0,\n",
    "    \"run_id\": str(uuid.uuid4()),\n",
    "    \"cost\": 0.0,\n",
    "    \"latency_ms\": 0.0,\n",
    "    \"approved\": False,\n",
    "    \"risk_level\": \"low\"\n",
    "}\n",
    "\n",
    "final_state = graph.invoke(initial_state)\n",
    "print(\"\\nFinal State:\")\n",
    "print(final_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50aa684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
