{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68ca06c9",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Short-Term Memory\n",
    "\n",
    "In LangGraph, **Short-Term Memory (STM)** is the **in-graph, ephemeral state** that exists **during the execution of a workflow** and is shared across nodes. It is the core mechanism by which LangGraph enables **context propagation, coordination, iterative reasoning, and control flow**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Conceptual Definition**\n",
    "\n",
    "> **Short-Term Memory = Graph State**\n",
    "\n",
    "It is the **authoritative working memory** of the graph.\n",
    "\n",
    "| Property    | Description                      |\n",
    "| ----------- | -------------------------------- |\n",
    "| Scope       | One graph execution (one thread) |\n",
    "| Lifetime    | From invocation → termination    |\n",
    "| Mutability  | Updated incrementally by nodes   |\n",
    "| Visibility  | Shared across all nodes          |\n",
    "| Persistence | Optional via checkpointing       |\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Why STM Is Essential**\n",
    "\n",
    "Without STM, nodes are isolated function calls.\n",
    "With STM, the graph becomes a **coherent cognitive system**.\n",
    "\n",
    "| Capability           | Enabled by STM                  |\n",
    "| -------------------- | ------------------------------- |\n",
    "| Multi-step reasoning | Accumulate intermediate results |\n",
    "| Agent coordination   | Shared context                  |\n",
    "| Loop control         | Track progress and termination  |\n",
    "| Tool orchestration   | Pass results between tools      |\n",
    "| Human-in-the-loop    | Inject corrections              |\n",
    "| Autonomy             | Maintain evolving plan          |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. How STM Is Represented**\n",
    "\n",
    "STM is defined by a **typed state schema**.\n",
    "\n",
    "```python\n",
    "from typing import TypedDict, List\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: List[str]\n",
    "    plan: str\n",
    "    result: str\n",
    "    step: int\n",
    "```\n",
    "\n",
    "This schema is the **contract** between all nodes.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. STM Lifecycle**\n",
    "\n",
    "```\n",
    "Initialize → Update → Merge → Read → Update → … → Finalize\n",
    "```\n",
    "\n",
    "Each node:\n",
    "\n",
    "1. **Reads** current state\n",
    "2. Performs computation\n",
    "3. **Returns partial update**\n",
    "4. LangGraph **merges updates** into global state\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Partial State Updates & Reducers**\n",
    "\n",
    "Nodes never replace the entire memory—only the fields they modify.\n",
    "\n",
    "```python\n",
    "def planner(state):\n",
    "    return {\"plan\": \"Search then summarize\"}\n",
    "```\n",
    "\n",
    "Reducers control **how updates merge**:\n",
    "\n",
    "```python\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: list\n",
    "\n",
    "State = Annotated[State, {\"messages\": add_messages}]\n",
    "```\n",
    "\n",
    "This allows **append-only memory**, conflict resolution, and controlled mutation.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. STM in Cyclic & Agentic Systems**\n",
    "\n",
    "STM enables **loop intelligence**:\n",
    "\n",
    "```python\n",
    "def should_continue(state):\n",
    "    return \"finish\" if state[\"step\"] > 5 else \"reason\"\n",
    "```\n",
    "\n",
    "The state itself **controls execution**.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. STM vs Long-Term Memory**\n",
    "\n",
    "| Dimension   | Short-Term Memory      | Long-Term Memory        |\n",
    "| ----------- | ---------------------- | ----------------------- |\n",
    "| Lifetime    | Single execution       | Across executions       |\n",
    "| Storage     | In-memory / checkpoint | Database / vector store |\n",
    "| Purpose     | Reasoning & control    | Knowledge retention     |\n",
    "| Speed       | Very fast              | Slower                  |\n",
    "| Consistency | Strong                 | Eventual                |\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Example: STM in a Reasoning Loop**\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "class State(TypedDict):\n",
    "    thought: str\n",
    "    step: int\n",
    "\n",
    "def reason(state):\n",
    "    return {\"thought\": f\"Step {state['step']}\", \"step\": state[\"step\"] + 1}\n",
    "\n",
    "def route(state):\n",
    "    return END if state[\"step\"] >= 3 else \"reason\"\n",
    "\n",
    "g = StateGraph(State)\n",
    "g.add_node(\"reason\", reason)\n",
    "g.set_entry_point(\"reason\")\n",
    "g.add_conditional_edges(\"reason\", route, {\"reason\": \"reason\", END: END})\n",
    "\n",
    "graph = g.compile()\n",
    "print(graph.invoke({\"thought\": \"\", \"step\": 0}))\n",
    "```\n",
    "\n",
    "The evolving `State` **is the short-term memory**.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Production Considerations**\n",
    "\n",
    "| Concern        | Solution                    |\n",
    "| -------------- | --------------------------- |\n",
    "| State growth   | Prune / summarize           |\n",
    "| Large memory   | Offload to long-term memory |\n",
    "| Crash recovery | Checkpoint store            |\n",
    "| Concurrency    | Thread-scoped STM           |\n",
    "| Debugging      | State inspection tools      |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Mental Model**\n",
    "\n",
    "LangGraph STM functions exactly like:\n",
    "\n",
    "> **Working memory in the human brain**\n",
    "\n",
    "It holds:\n",
    "\n",
    "* current thoughts\n",
    "* plans\n",
    "* observations\n",
    "* intermediate conclusions\n",
    "\n",
    "and evolves continuously until the task completes.\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95aa3409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.graph import add_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176b9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    thoughts: Annotated[List[str], add_messages]\n",
    "    step: int\n",
    "\n",
    "def reason(state: State):\n",
    "    new_thought = f\"Reasoning at step {state['step']}\"\n",
    "    return {\n",
    "        \"thoughts\": [new_thought],\n",
    "        \"step\": state[\"step\"] + 1\n",
    "    }\n",
    "\n",
    "def decide(state: State):\n",
    "    if state[\"step\"] >= 4:\n",
    "        return END\n",
    "    return \"reason\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd54d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"reason\", reason)\n",
    "builder.set_entry_point(\"reason\")\n",
    "\n",
    "builder.add_conditional_edges(\"reason\", decide, {\n",
    "    \"reason\": \"reason\",\n",
    "    END: END\n",
    "})\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a86d267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thoughts': [HumanMessage(content='Reasoning at step 0', additional_kwargs={}, response_metadata={}, id='39b8182c-4155-4f8f-8dd6-f3ffb18c5657'), HumanMessage(content='Reasoning at step 1', additional_kwargs={}, response_metadata={}, id='9f0765a8-b162-4cbc-aa66-96eb642e85c7'), HumanMessage(content='Reasoning at step 2', additional_kwargs={}, response_metadata={}, id='f912833d-3c19-4e89-9542-1d50f9614282'), HumanMessage(content='Reasoning at step 3', additional_kwargs={}, response_metadata={}, id='1ee5ffac-1bcc-4c02-be35-f4512a87a111')], 'step': 4}\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"thoughts\": [], \"step\": 0})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa797f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
