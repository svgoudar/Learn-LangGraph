{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475edeb4",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## State Persistence\n",
    "\n",
    "**State persistence** in LangGraph is the mechanism by which the **entire execution state of a graph is stored, versioned, and recoverable across time, failures, and user interactions**.\n",
    "It transforms LangGraph from a simple workflow engine into a **reliable, long-running, production-grade system**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Why State Persistence Is Necessary**\n",
    "\n",
    "LLM workflows are **not atomic**. They involve:\n",
    "\n",
    "* multi-step reasoning\n",
    "* tool calls\n",
    "* human approvals\n",
    "* long-running processes\n",
    "* failure recovery\n",
    "* multi-session conversations\n",
    "\n",
    "Without persistence, **any crash destroys the workflow**.\n",
    "\n",
    "| With Persistence  | Without Persistence |\n",
    "| ----------------- | ------------------- |\n",
    "| Survives restarts | Lost progress       |\n",
    "| Supports recovery | Must restart        |\n",
    "| Enables debugging | No traceability     |\n",
    "| Human-in-the-loop | Impossible          |\n",
    "\n",
    "---\n",
    "\n",
    "### **2. What Is Persisted**\n",
    "\n",
    "LangGraph persists **execution-level state**:\n",
    "\n",
    "| Component          | Description                |\n",
    "| ------------------ | -------------------------- |\n",
    "| Global State       | The shared TypedDict state |\n",
    "| Node Outputs       | Partial updates from nodes |\n",
    "| Execution Position | Current node               |\n",
    "| Graph Structure    | Versioned graph definition |\n",
    "| Thread ID          | Workflow identity          |\n",
    "| Checkpoints        | Time-ordered snapshots     |\n",
    "| Metadata           | timestamps, user, config   |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Persistence Architecture**\n",
    "\n",
    "```\n",
    "Client Request\n",
    "     ↓\n",
    "LangGraph Runtime\n",
    "     ↓\n",
    "Checkpoint Manager\n",
    "     ↓\n",
    "State Store (Redis / Postgres / DynamoDB)\n",
    "```\n",
    "\n",
    "Each transition produces a **checkpoint**:\n",
    "\n",
    "```\n",
    "(State_t, Node, Metadata) → Persistent Storage\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Checkpointing Model**\n",
    "\n",
    "Every node execution creates a snapshot:\n",
    "\n",
    "```text\n",
    "Checkpoint = {\n",
    "  thread_id,\n",
    "  node_name,\n",
    "  state,\n",
    "  timestamp,\n",
    "  metadata\n",
    "}\n",
    "```\n",
    "\n",
    "This enables:\n",
    "\n",
    "* replay\n",
    "* rollback\n",
    "* debugging\n",
    "* recovery\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Enabling Persistence in Code**\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "checkpointer = SqliteSaver(\"state.db\")\n",
    "\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "```\n",
    "\n",
    "Running with identity:\n",
    "\n",
    "```python\n",
    "config = {\"configurable\": {\"thread_id\": \"user-123\"}}\n",
    "graph.invoke(input_state, config)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Recovery & Resume**\n",
    "\n",
    "If execution crashes:\n",
    "\n",
    "```python\n",
    "graph.invoke(input_state, config)\n",
    "```\n",
    "\n",
    "LangGraph **resumes from the latest checkpoint** for that thread.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Long-Term Conversations**\n",
    "\n",
    "Because state is persisted:\n",
    "\n",
    "* conversations are **not tied to process memory**\n",
    "* multiple servers can share the same workflow\n",
    "* horizontal scaling is safe\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Human-in-the-Loop Support**\n",
    "\n",
    "Execution can pause:\n",
    "\n",
    "```\n",
    "Reason → Analyze → [WAIT FOR HUMAN] → Continue\n",
    "```\n",
    "\n",
    "After human input, the same thread resumes.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Storage Backends**\n",
    "\n",
    "| Backend    | Use Case     |\n",
    "| ---------- | ------------ |\n",
    "| SQLite     | local dev    |\n",
    "| PostgreSQL | production   |\n",
    "| Redis      | high-speed   |\n",
    "| DynamoDB   | serverless   |\n",
    "| S3         | cold storage |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Production Benefits**\n",
    "\n",
    "| Capability           | Enabled |\n",
    "| -------------------- | ------- |\n",
    "| Crash recovery       | ✔       |\n",
    "| Auditing             | ✔       |\n",
    "| Compliance           | ✔       |\n",
    "| Multi-session agents | ✔       |\n",
    "| Autonomous systems   | ✔       |\n",
    "| Enterprise workflows | ✔       |\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Mental Model**\n",
    "\n",
    "> LangGraph persistence = **transaction log for intelligence**\n",
    "\n",
    "Each step of thinking becomes a **durable fact**.\n",
    "\n",
    "---\n",
    "\n",
    "### **12. Summary**\n",
    "\n",
    "State persistence converts LangGraph from:\n",
    "\n",
    "> *a workflow runner* → **an intelligent distributed system**\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d19042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    count: int\n",
    "    done: bool\n",
    "\n",
    "def increment(state: State):\n",
    "    print(\"Incrementing:\", state[\"count\"])\n",
    "    return {\"count\": state[\"count\"] + 1}\n",
    "\n",
    "def check_done(state: State):\n",
    "    done = state[\"count\"] >= 5\n",
    "    print(\"Done?\", done)\n",
    "    return {\"done\": done}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e4512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"inc\", increment)\n",
    "builder.add_node(\"check\", check_done)\n",
    "\n",
    "builder.set_entry_point(\"inc\")\n",
    "builder.add_edge(\"inc\", \"check\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"check\",\n",
    "    lambda s: END if s[\"done\"] else \"inc\",\n",
    "    {\"inc\": \"inc\", END: END}\n",
    ")\n",
    "\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e462c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incrementing: 0\n",
      "Done? False\n",
      "Incrementing: 1\n",
      "Done? False\n",
      "Incrementing: 2\n",
      "Done? False\n",
      "Incrementing: 3\n",
      "Done? False\n",
      "Incrementing: 4\n",
      "Done? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'count': 5, 'done': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"demo\"}}\n",
    "\n",
    "graph.invoke({\"count\": 0, \"done\": False}, config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
