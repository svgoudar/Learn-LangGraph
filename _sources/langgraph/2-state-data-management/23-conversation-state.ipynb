{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "700d05da",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## **Conversation State in LangGraph**\n",
    "\n",
    "In LangGraph, **Conversation State** is the structured, persistent memory object that represents **everything the system knows about an ongoing interaction**.\n",
    "It enables **multi-turn reasoning, agent coordination, long-running workflows, and recovery across executions**.\n",
    "\n",
    "At a systems level, conversation state is the **single source of truth** driving execution, routing, memory, and behavior.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Formal Definition**\n",
    "\n",
    "> **Conversation State** = Typed, versioned, persistent data structure that is **read and updated by every node** during graph execution.\n",
    "\n",
    "It acts as the **memory + control plane** of the entire workflow.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Why Conversation State Is Necessary**\n",
    "\n",
    "Without conversation state, workflows are:\n",
    "\n",
    "* Stateless\n",
    "* Single-turn\n",
    "* Fragile\n",
    "* Non-recoverable\n",
    "\n",
    "With conversation state, LangGraph supports:\n",
    "\n",
    "| Capability          | Enabled by State |\n",
    "| ------------------- | ---------------- |\n",
    "| Multi-turn dialogue | Yes              |\n",
    "| Tool coordination   | Yes              |\n",
    "| Agent collaboration | Yes              |\n",
    "| Looping & planning  | Yes              |\n",
    "| Checkpoint & resume | Yes              |\n",
    "| Human-in-the-loop   | Yes              |\n",
    "| Long-running tasks  | Yes              |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Structure of Conversation State**\n",
    "\n",
    "Conversation state is **explicitly typed**.\n",
    "\n",
    "```python\n",
    "from typing import TypedDict, List\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: List[dict]\n",
    "    user_goal: str\n",
    "    plan: str\n",
    "    last_action: str\n",
    "    tool_results: dict\n",
    "    done: bool\n",
    "```\n",
    "\n",
    "Each node:\n",
    "\n",
    "* **Reads** the current state\n",
    "* **Returns partial updates**\n",
    "* LangGraph **merges updates deterministically**\n",
    "\n",
    "---\n",
    "\n",
    "### **4. How State Flows Through the Graph**\n",
    "\n",
    "```\n",
    "User Input → State → Node A → Updated State → Node B → Updated State → ...\n",
    "```\n",
    "\n",
    "No node communicates directly with another.\n",
    "All coordination happens through **state transitions**.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Message History as Conversation State**\n",
    "\n",
    "A common pattern:\n",
    "\n",
    "```python\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: list\n",
    "\n",
    "def chat_node(state):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": add_messages(state[\"messages\"], response)}\n",
    "```\n",
    "\n",
    "This allows the model to reason over the **entire conversation context**.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. State Persistence & Recovery**\n",
    "\n",
    "LangGraph supports durable state using **checkpoint stores**.\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "checkpointer = SqliteSaver(\"conversations.db\")\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "```\n",
    "\n",
    "Capabilities enabled:\n",
    "\n",
    "| Feature          | Description    |\n",
    "| ---------------- | -------------- |\n",
    "| Crash recovery   | Resume exactly |\n",
    "| Replay           | Debugging      |\n",
    "| Auditing         | Full history   |\n",
    "| Long-term memory | Yes            |\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Conversation State in Cyclic Graphs**\n",
    "\n",
    "State controls looping behavior:\n",
    "\n",
    "```python\n",
    "def router(state):\n",
    "    if state[\"done\"]:\n",
    "        return END\n",
    "    return \"reason\"\n",
    "```\n",
    "\n",
    "State is the **control signal** for iteration.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Multi-Agent Conversation State**\n",
    "\n",
    "Agents collaborate **through shared state**.\n",
    "\n",
    "| Agent      | State Fields |\n",
    "| ---------- | ------------ |\n",
    "| Planner    | plan         |\n",
    "| Researcher | evidence     |\n",
    "| Executor   | result       |\n",
    "| Critic     | feedback     |\n",
    "\n",
    "This allows **structured agent communication**.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Production Design Principles**\n",
    "\n",
    "| Principle       | Rationale            |\n",
    "| --------------- | -------------------- |\n",
    "| Typed schema    | Safety & correctness |\n",
    "| Partial updates | Efficiency           |\n",
    "| Immutability    | Debugging & replay   |\n",
    "| Persistence     | Fault tolerance      |\n",
    "| Versioning      | Upgrades             |\n",
    "| Encryption      | Security             |\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Mental Model**\n",
    "\n",
    "Conversation state in LangGraph behaves like:\n",
    "\n",
    "> **A distributed control system's memory register**\n",
    "\n",
    "It is both:\n",
    "\n",
    "* **Memory** (what the system knows)\n",
    "* **Control logic** (how the system decides)\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Comparison**\n",
    "\n",
    "| Traditional Chat | LangGraph              |\n",
    "| ---------------- | ---------------------- |\n",
    "| Prompt string    | Structured state       |\n",
    "| Hidden memory    | Explicit memory        |\n",
    "| No recovery      | Durable recovery       |\n",
    "| Single LLM       | Multi-agent system     |\n",
    "| Linear flow      | Cyclic autonomous flow |\n",
    "\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3504cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: List[dict]\n",
    "    plan: str\n",
    "    done: bool\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def reason(state: State):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\n",
    "        \"messages\": add_messages(state[\"messages\"], response),\n",
    "        \"plan\": \"refine\",\n",
    "        \"done\": False\n",
    "    }\n",
    "\n",
    "def reflect(state: State):\n",
    "    critique = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": \"Check if the answer is complete.\"},\n",
    "        *state[\"messages\"]\n",
    "    ])\n",
    "    messages = add_messages(state[\"messages\"], critique)\n",
    "    done = \"complete\" in critique.content.lower()\n",
    "    return {\"messages\": messages, \"done\": done}\n",
    "\n",
    "from langgraph.graph import END\n",
    "\n",
    "def router(state: State):\n",
    "    return END if state[\"done\"] else \"reason\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee72b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"reason\", reason)\n",
    "builder.add_node(\"reflect\", reflect)\n",
    "\n",
    "builder.set_entry_point(\"reason\")\n",
    "builder.add_edge(\"reason\", \"reflect\")\n",
    "\n",
    "builder.add_conditional_edges(\"reflect\", router, {\n",
    "    \"reason\": \"reason\",\n",
    "    END: END\n",
    "})\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e35e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Explain neural networks simply.\"}],\n",
    "    \"plan\": \"\",\n",
    "    \"done\": False\n",
    "}\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}, \"recursion_limit\": 50}\n",
    "result = graph.invoke(input_state, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd76df5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Explain neural networks simply.', additional_kwargs={}, response_metadata={}, id='c93358c2-4e99-42a1-8f56-05f5a2d468c7'),\n",
       "  AIMessage(content='Sure! Neural networks are a type of computer program modeled after the way our brains work. They are designed to recognize patterns and learn from data.\\n\\nHere\\'s a simple breakdown of how they work:\\n\\n1. **Neurons**: Think of a neural network as a web of interconnected units called neurons. Just like human neurons, these units take in information, process it, and pass on the result.\\n\\n2. **Layers**: Neural networks consist of layers. The first layer (input layer) receives data, like images or text. The middle layers (hidden layers) process this information, and the last layer (output layer) gives the final results, such as classifications or predictions.\\n\\n3. **Weights and Biases**: Each connection between neurons has a weight, which determines the importance of the signal being passed. There are also biases that help adjust the output. During training, the network learns by adjusting these weights and biases based on the data it processes.\\n\\n4. **Learning**: To teach a neural network, you feed it a lot of examples. It adjusts its weights and biases to minimize errors in its predictions. This process is called training. The better the network learns to adjust, the more accurate its predictions become.\\n\\n5. **Activation Functions**: After processing the input, neurons use activation functions to decide whether to \"fire\" or pass on their signal. This helps the network make complex decisions.\\n\\nIn summary, neural networks are powerful tools that learn from data to recognize patterns and make predictions, much like how our brains process information!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 310, 'prompt_tokens': 12, 'total_tokens': 322, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_c4585b5b9c', 'id': 'chatcmpl-CrlZdITANaoTG3UjV5Gb4JQM6daI5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b6540-aba5-7fc1-9dec-5a17e5ebd855-0', usage_metadata={'input_tokens': 12, 'output_tokens': 310, 'total_tokens': 322, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  AIMessage(content='The answer is quite complete and provides a clear, simplified explanation of neural networks. It covers the key components, including neurons, layers, weights, biases, learning, and activation functions. Each concept is explained in an accessible way, making it understandable for someone without a technical background. If you have any specific areas you’d like to know more about or if you want a different level of detail, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 337, 'total_tokens': 421, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-CrlZkRzqa3k9YX5Femul646enAlAK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b6540-c8eb-7de1-b011-a386571dece8-0', usage_metadata={'input_tokens': 337, 'output_tokens': 84, 'total_tokens': 421, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'plan': 'refine',\n",
       " 'done': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409c0209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
